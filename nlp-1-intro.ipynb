{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f9fd28",
   "metadata": {
    "id": "R67NmC2GWaoR",
    "papermill": {
     "duration": 0.038181,
     "end_time": "2023-02-23T00:58:17.497176",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.458995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text manipulation and extraction in Python\n",
    "\n",
    "This notebook introduces the basic operation on strings that can be done with the Python programming language.\n",
    "The notebook then focuses on text manipulation and extraction from different sources:\n",
    "- Text files\n",
    "- Web\n",
    "- PDF documents\n",
    "- OCR scanned PDF documents\n",
    "\n",
    "For an introduction or recap on Python, refer to the WeBeep page of this course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f545ff0",
   "metadata": {
    "id": "H9fk15RybKqy",
    "papermill": {
     "duration": 0.03569,
     "end_time": "2023-02-23T00:58:17.568368",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.532678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Strings and lists\n",
    "\n",
    "A 'string' is simply a sequence of characters used to represent a document in a programming language such as Python.\n",
    "- Let's create a Python variable called 'doc' that contains a short document as a string.\n",
    "- After defining the variable, we repeat its name so as to print out its content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caffc21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:17.641144Z",
     "iopub.status.busy": "2023-02-23T00:58:17.640304Z",
     "iopub.status.idle": "2023-02-23T00:58:17.654295Z",
     "shell.execute_reply": "2023-02-23T00:58:17.653209Z"
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1677006267697,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "XzuBscVnbKqz",
    "outputId": "b68dfe1c-f5a2-4251-b5fc-c8296b99249a",
    "papermill": {
     "duration": 0.05307,
     "end_time": "2023-02-23T00:58:17.656692",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.603622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = 'In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell'\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfcfe2",
   "metadata": {
    "id": "PILAgmKDbKqz",
    "papermill": {
     "duration": 0.035885,
     "end_time": "2023-02-23T00:58:17.728375",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.692490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can calculate the length of the string (in characters) by using the len() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c57cac35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:17.801640Z",
     "iopub.status.busy": "2023-02-23T00:58:17.800637Z",
     "iopub.status.idle": "2023-02-23T00:58:17.808390Z",
     "shell.execute_reply": "2023-02-23T00:58:17.807256Z"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1677006270495,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "B0KzLRCjbKq0",
    "outputId": "a461e867-fd4f-4533-fd8f-b692af7346d9",
    "papermill": {
     "duration": 0.047037,
     "end_time": "2023-02-23T00:58:17.810821",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.763784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a4e32",
   "metadata": {
    "id": "NlH3zCkHbKq0",
    "papermill": {
     "duration": 0.036155,
     "end_time": "2023-02-23T00:58:17.882710",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.846555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can divide up the sentence into individual words by splitting it on whitespace (spaces, tabs, etc.). \n",
    "- This process is called 'tokenisation':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e8a929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:17.958672Z",
     "iopub.status.busy": "2023-02-23T00:58:17.957924Z",
     "iopub.status.idle": "2023-02-23T00:58:17.964727Z",
     "shell.execute_reply": "2023-02-23T00:58:17.963459Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006272209,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "826CWmTnbKq0",
    "outputId": "f3c559a9-e839-42d7-ea36-045a3e17c34d",
    "papermill": {
     "duration": 0.047289,
     "end_time": "2023-02-23T00:58:17.966976",
     "exception": false,
     "start_time": "2023-02-23T00:58:17.919687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'a',\n",
       " 'hole',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'there',\n",
       " 'lived',\n",
       " 'a',\n",
       " 'hobbit.',\n",
       " 'Not',\n",
       " 'a',\n",
       " 'nasty,',\n",
       " 'dirty,',\n",
       " 'wet',\n",
       " 'hole,',\n",
       " 'filled',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ends',\n",
       " 'of',\n",
       " 'worms',\n",
       " 'and',\n",
       " 'an',\n",
       " 'oozy',\n",
       " 'smell']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915defd",
   "metadata": {
    "id": "_Fky0cvtbKq0",
    "papermill": {
     "duration": 0.036118,
     "end_time": "2023-02-23T00:58:18.039163",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.003045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that the ouptut above is in the form of comma-separated list of strings [s1,s2,...,sn]\n",
    "- The layout above is vertical, but if you use print() command you can get a more compact horizontal ouptut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15575f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:18.115491Z",
     "iopub.status.busy": "2023-02-23T00:58:18.114688Z",
     "iopub.status.idle": "2023-02-23T00:58:18.121445Z",
     "shell.execute_reply": "2023-02-23T00:58:18.120070Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006272772,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "UwTtRQIwbKq1",
    "outputId": "d3dbf5ff-a2c0-49ce-a328-f0997f0718e8",
    "papermill": {
     "duration": 0.047512,
     "end_time": "2023-02-23T00:58:18.123698",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.076186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'a', 'hole', 'in', 'the', 'ground', 'there', 'lived', 'a', 'hobbit.', 'Not', 'a', 'nasty,', 'dirty,', 'wet', 'hole,', 'filled', 'with', 'the', 'ends', 'of', 'worms', 'and', 'an', 'oozy', 'smell']\n"
     ]
    }
   ],
   "source": [
    "print(doc.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1c86f",
   "metadata": {
    "id": "X7VvLRsobKq1",
    "papermill": {
     "duration": 0.035215,
     "end_time": "2023-02-23T00:58:18.195862",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.160647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We didn't have to split the sentence on whitespace, we could have split it around any substring. \n",
    "- For example we could split on the comma ',' character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76548560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:18.269353Z",
     "iopub.status.busy": "2023-02-23T00:58:18.268385Z",
     "iopub.status.idle": "2023-02-23T00:58:18.274431Z",
     "shell.execute_reply": "2023-02-23T00:58:18.273658Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006273242,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "ahRXQem1bKq1",
    "outputId": "7ac1c4e4-64a8-47f2-8a6b-bcc39f12fb94",
    "papermill": {
     "duration": 0.044579,
     "end_time": "2023-02-23T00:58:18.276427",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.231848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a hole in the ground there lived a hobbit. Not a nasty',\n",
       " ' dirty',\n",
       " ' wet hole',\n",
       " ' filled with the ends of worms and an oozy smell']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa88a9",
   "metadata": {
    "id": "04A8J71QbKq1",
    "papermill": {
     "duration": 0.035401,
     "end_time": "2023-02-23T00:58:18.347459",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.312058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How many words are there in the document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acfa01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:18.421142Z",
     "iopub.status.busy": "2023-02-23T00:58:18.420695Z",
     "iopub.status.idle": "2023-02-23T00:58:18.426918Z",
     "shell.execute_reply": "2023-02-23T00:58:18.426023Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006273961,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "03XDB4C1bKq2",
    "outputId": "54f0bb30-9eff-46e7-a478-275c9fb48bdf",
    "papermill": {
     "duration": 0.045539,
     "end_time": "2023-02-23T00:58:18.428976",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.383437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = doc.split()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd3aa1",
   "metadata": {
    "id": "3Bwb2-TTbKq2",
    "papermill": {
     "duration": 0.036014,
     "end_time": "2023-02-23T00:58:18.500949",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.464935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Often in text-processing pipelines we convert all text to lower-case. \n",
    "- Since the sentence is almost all in lower-case already, let's convert it to upper-case instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4eb291b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:18.574729Z",
     "iopub.status.busy": "2023-02-23T00:58:18.574035Z",
     "iopub.status.idle": "2023-02-23T00:58:18.580717Z",
     "shell.execute_reply": "2023-02-23T00:58:18.579590Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006274360,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "-utEyCjZbKq2",
    "outputId": "f218c87b-723c-4e8a-9007-018f58c22635",
    "papermill": {
     "duration": 0.046554,
     "end_time": "2023-02-23T00:58:18.583292",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.536738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IN A HOLE IN THE GROUND THERE LIVED A HOBBIT. NOT A NASTY, DIRTY, WET HOLE, FILLED WITH THE ENDS OF WORMS AND AN OOZY SMELL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c118b",
   "metadata": {
    "id": "qgR1MpJWbKq2",
    "papermill": {
     "duration": 0.035929,
     "end_time": "2023-02-23T00:58:18.655448",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.619519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading text from a file\n",
    "Let's now read in a longer document form a text file 'Alice_Chapter1.txt'\n",
    "\n",
    "- Make sure you have downloaded the file \"Alice_Chapter1.txt\" from the \"docs\" directory in the WeBeep directory where you found this notebook (I'd suggest you downlod the entire directory each time to be sure every file is in the right place).\n",
    "- If you are using Google Colab, you will then need to upload the file by clicking on the Folder icon to the left of the notebook, then clicking on the Upload icon, and finding the file on your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc5e9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:18.730917Z",
     "iopub.status.busy": "2023-02-23T00:58:18.730066Z",
     "iopub.status.idle": "2023-02-23T00:58:18.749066Z",
     "shell.execute_reply": "2023-02-23T00:58:18.748070Z"
    },
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1677006546257,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Zw9JB10EbKq2",
    "papermill": {
     "duration": 0.060805,
     "end_time": "2023-02-23T00:58:18.752780",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.691975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/nlp-practical1/docs/Alice_Chapter1.txt\") as f:\n",
    "    doc2 = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ccac8",
   "metadata": {
    "id": "4gPJhHrEbKq3",
    "papermill": {
     "duration": 0.042282,
     "end_time": "2023-02-23T00:58:18.840523",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.798241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Print out the text as Python sees it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b07257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:18.916761Z",
     "iopub.status.busy": "2023-02-23T00:58:18.915560Z",
     "iopub.status.idle": "2023-02-23T00:58:18.923372Z",
     "shell.execute_reply": "2023-02-23T00:58:18.922088Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006549741,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "27CsU1gbbKq3",
    "outputId": "d3b95bc1-35ef-40bd-e3a3-83550944e81e",
    "papermill": {
     "duration": 0.047879,
     "end_time": "2023-02-23T00:58:18.925796",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.877917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,\\' thought Alice `without pictures or conversation?\\'\\nSo she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\\n\\nThere was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, `Oh dear! Oh dear! I shall be late!\\' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how in the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. She took down a jar from one of the shelves as she passed; it was labelled `ORANGE MARMALADE\\', but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.\\n\\n`Well!\\' thought Alice to herself, `after such a fall as this, I shall think nothing of tumbling down stairs! How brave they\\'ll all think me at home! Why, I wouldn\\'t say anything about it, even if I fell off the top of the house!\\' (Which was very likely true.)\\n\\nDown, down, down. Would the fall never come to an end! `I wonder how many miles I\\'ve fallen by this time?\\' she said aloud. `I must be getting somewhere near the centre of the earth. Let me see: that would be four thousand miles down, I think--\\' (for, you see, Alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a very good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) `--yes, that\\'s about the right distance--but then I wonder what Latitude or Longitude I\\'ve got to?\\' (Alice had no idea what Latitude was, or Longitude either, but thought they were nice grand words to say.)\\n\\nPresently she began again. `I wonder if I shall fall right through the earth! How funny it\\'ll seem to come out among the people that walk with their heads downward! The Antipathies, I think--\\' (she was rather glad there was no one listening, this time, as it didn\\'t sound at all the right word) `--but I shall have to ask them what the name of the country is, you know. Please, Ma\\'am, is this New Zealand or Australia?\\' (and she tried to curtsey as she spoke--fancy curtseying as you\\'re falling through the air! Do you think you could manage it?) `And what an ignorant little girl she\\'ll think me for asking! No, it\\'ll never do to ask: perhaps I shall see it written up somewhere.\\'\\n\\nDown, down, down. There was nothing else to do, so Alice soon began talking again. `Dinah\\'ll miss me very much to-night, I should think!\\' (Dinah was the cat.) `I hope they\\'ll remember her saucer of milk at tea-time. Dinah my dear! I wish you were down here with me! There are no mice in the air, I\\'m afraid, but you might catch a bat, and that\\'s very like a mouse, you know. But do cats eat bats, I wonder?\\' And here Alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, `Do cats eat bats? Do cats eat bats?\\' and sometimes, `Do bats eat cats?\\' for, you see, as she couldn\\'t answer either question, it didn\\'t much matter which way she put it. She felt that she was dozing off, and had just begun to dream that she was walking hand in hand with Dinah, and saying to her very earnestly, `Now, Dinah, tell me the truth: did you ever eat a bat?\\' when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over.\\n\\nAlice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the White Rabbit was still in sight, hurrying down it. There was not a moment to be lost: away went Alice like the wind, and was just in time to hear it say, as it turned a corner, `Oh my ears and whiskers, how late it\\'s getting!\\' She was close behind it when she turned the corner, but the Rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof.\\n\\nThere were doors all round the hall, but they were all locked; and when Alice had been all the way down one side and up the other, trying every door, she walked sadly down the middle, wondering how she was ever to get out again.\\n\\nSuddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and Alice\\'s first thought was that it might belong to one of the doors of the hall; but, alas! either the locks were too large, or the key was too small, but at any rate it would not open any of them. However, on the second time round, she came upon a low curtain she had not noticed before, and behind it was a little door about fifteen inches high: she tried the little golden key in the lock, and to her great delight it fitted!\\n\\nAlice opened the door and found that it led into a small passage, not much larger than a rat-hole: she knelt down and looked along the passage into the loveliest garden you ever saw. How she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head though the doorway; `and even if my head would go through,\\' thought poor Alice, `it would be of very little use without my shoulders. Oh, how I wish I could shut up like a telescope! I think I could, if I only know how to begin.\\' For, you see, so many out-of-the-way things had happened lately, that Alice had begun to think that very few things indeed were really impossible.\\n\\nThere seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (`which certainly was not here before,\\' said Alice,) and round the neck of the bottle was a paper label, with the words `DRINK ME\\' beautifully printed on it in large letters.\\n\\nIt was all very well to say `Drink me,\\' but the wise little Alice was not going to do that in a hurry. `No, I\\'ll look first,\\' she said, `and see whether it\\'s marked \"poison\" or not\\'; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they would not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger very deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked `poison,\\' it is almost certain to disagree with you, sooner or later.\\n\\nHowever, this bottle was not marked `poison,\\' so Alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,) she very soon finished it off.\\n\\n`What a curious feeling!\\' said Alice; `I must be shutting up like a telescope.\\'\\nAnd so it was indeed: she was now only ten inches high, and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden. First, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; `for it might end, you know,\\' said Alice to herself, `in my going out altogether, like a candle. I wonder what I should be like then?\\' And she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.\\n\\nAfter a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor Alice! when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried.\\n\\n`Come, there\\'s no use in crying like that!\\' said Alice to herself, rather sharply; `I advise you to leave off this minute!\\' She generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people. `But it\\'s no use now,\\' thought poor Alice, `to pretend to be two people! Why, there\\'s hardly enough of me left to make one respectable person!\\'\\n\\nSoon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words `EAT ME\\' were beautifully marked in currants. `Well, I\\'ll eat it,\\' said Alice, `and if it makes me grow larger, I can reach the key; and if it makes me grow smaller, I can creep under the door; so either way I\\'ll get into the garden, and I don\\'t care which happens!\\'\\n\\nShe ate a little bit, and said anxiously to herself, `Which way? Which way?\\', holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size: to be sure, this generally happens when one eats cake, but Alice had got so much into the way of expecting nothing but out-of-the-way things to happen, that it seemed quite dull and stupid for life to go on in the common way.\\n\\nSo she set to work, and very soon finished off the cake.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b96a17",
   "metadata": {
    "id": "JEDHeg0EbKq3",
    "papermill": {
     "duration": 0.036283,
     "end_time": "2023-02-23T00:58:19.000024",
     "exception": false,
     "start_time": "2023-02-23T00:58:18.963741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note all the backslash characters '\\\\' in the text above.  \n",
    "- Python stores text as one big string (sequence of characters). \n",
    "- Special characters such as newlines and tabs are represented by '\\\\n' and '\\\\t' respectively.\n",
    "- The quote character is used to mark the start and end of the string ('string'), so quote characters that are present in the string are prefixed by a backslash to prevent the string from ending early ('str\\\\'ing'). \n",
    "- Using the print() command, we can output the string in a format that we're more used to seeing it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f29b73c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:19.076089Z",
     "iopub.status.busy": "2023-02-23T00:58:19.075655Z",
     "iopub.status.idle": "2023-02-23T00:58:19.081463Z",
     "shell.execute_reply": "2023-02-23T00:58:19.080258Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677006551233,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "3m9q8V4QbKq3",
    "outputId": "d3f0cbdc-0a43-47c2-dc10-885f461fc87e",
    "papermill": {
     "duration": 0.048639,
     "end_time": "2023-02-23T00:58:19.085121",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.036482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n",
      "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\n",
      "\n",
      "There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, `Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\n",
      "\n",
      "In another moment down went Alice after it, never once considering how in the world she was to get out again.\n",
      "\n",
      "The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.\n",
      "\n",
      "Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. She took down a jar from one of the shelves as she passed; it was labelled `ORANGE MARMALADE', but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.\n",
      "\n",
      "`Well!' thought Alice to herself, `after such a fall as this, I shall think nothing of tumbling down stairs! How brave they'll all think me at home! Why, I wouldn't say anything about it, even if I fell off the top of the house!' (Which was very likely true.)\n",
      "\n",
      "Down, down, down. Would the fall never come to an end! `I wonder how many miles I've fallen by this time?' she said aloud. `I must be getting somewhere near the centre of the earth. Let me see: that would be four thousand miles down, I think--' (for, you see, Alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a very good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) `--yes, that's about the right distance--but then I wonder what Latitude or Longitude I've got to?' (Alice had no idea what Latitude was, or Longitude either, but thought they were nice grand words to say.)\n",
      "\n",
      "Presently she began again. `I wonder if I shall fall right through the earth! How funny it'll seem to come out among the people that walk with their heads downward! The Antipathies, I think--' (she was rather glad there was no one listening, this time, as it didn't sound at all the right word) `--but I shall have to ask them what the name of the country is, you know. Please, Ma'am, is this New Zealand or Australia?' (and she tried to curtsey as she spoke--fancy curtseying as you're falling through the air! Do you think you could manage it?) `And what an ignorant little girl she'll think me for asking! No, it'll never do to ask: perhaps I shall see it written up somewhere.'\n",
      "\n",
      "Down, down, down. There was nothing else to do, so Alice soon began talking again. `Dinah'll miss me very much to-night, I should think!' (Dinah was the cat.) `I hope they'll remember her saucer of milk at tea-time. Dinah my dear! I wish you were down here with me! There are no mice in the air, I'm afraid, but you might catch a bat, and that's very like a mouse, you know. But do cats eat bats, I wonder?' And here Alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, `Do cats eat bats? Do cats eat bats?' and sometimes, `Do bats eat cats?' for, you see, as she couldn't answer either question, it didn't much matter which way she put it. She felt that she was dozing off, and had just begun to dream that she was walking hand in hand with Dinah, and saying to her very earnestly, `Now, Dinah, tell me the truth: did you ever eat a bat?' when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over.\n",
      "\n",
      "Alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the White Rabbit was still in sight, hurrying down it. There was not a moment to be lost: away went Alice like the wind, and was just in time to hear it say, as it turned a corner, `Oh my ears and whiskers, how late it's getting!' She was close behind it when she turned the corner, but the Rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof.\n",
      "\n",
      "There were doors all round the hall, but they were all locked; and when Alice had been all the way down one side and up the other, trying every door, she walked sadly down the middle, wondering how she was ever to get out again.\n",
      "\n",
      "Suddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and Alice's first thought was that it might belong to one of the doors of the hall; but, alas! either the locks were too large, or the key was too small, but at any rate it would not open any of them. However, on the second time round, she came upon a low curtain she had not noticed before, and behind it was a little door about fifteen inches high: she tried the little golden key in the lock, and to her great delight it fitted!\n",
      "\n",
      "Alice opened the door and found that it led into a small passage, not much larger than a rat-hole: she knelt down and looked along the passage into the loveliest garden you ever saw. How she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head though the doorway; `and even if my head would go through,' thought poor Alice, `it would be of very little use without my shoulders. Oh, how I wish I could shut up like a telescope! I think I could, if I only know how to begin.' For, you see, so many out-of-the-way things had happened lately, that Alice had begun to think that very few things indeed were really impossible.\n",
      "\n",
      "There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (`which certainly was not here before,' said Alice,) and round the neck of the bottle was a paper label, with the words `DRINK ME' beautifully printed on it in large letters.\n",
      "\n",
      "It was all very well to say `Drink me,' but the wise little Alice was not going to do that in a hurry. `No, I'll look first,' she said, `and see whether it's marked \"poison\" or not'; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they would not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger very deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked `poison,' it is almost certain to disagree with you, sooner or later.\n",
      "\n",
      "However, this bottle was not marked `poison,' so Alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,) she very soon finished it off.\n",
      "\n",
      "`What a curious feeling!' said Alice; `I must be shutting up like a telescope.'\n",
      "And so it was indeed: she was now only ten inches high, and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden. First, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; `for it might end, you know,' said Alice to herself, `in my going out altogether, like a candle. I wonder what I should be like then?' And she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.\n",
      "\n",
      "After a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor Alice! when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried.\n",
      "\n",
      "`Come, there's no use in crying like that!' said Alice to herself, rather sharply; `I advise you to leave off this minute!' She generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people. `But it's no use now,' thought poor Alice, `to pretend to be two people! Why, there's hardly enough of me left to make one respectable person!'\n",
      "\n",
      "Soon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words `EAT ME' were beautifully marked in currants. `Well, I'll eat it,' said Alice, `and if it makes me grow larger, I can reach the key; and if it makes me grow smaller, I can creep under the door; so either way I'll get into the garden, and I don't care which happens!'\n",
      "\n",
      "She ate a little bit, and said anxiously to herself, `Which way? Which way?', holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size: to be sure, this generally happens when one eats cake, but Alice had got so much into the way of expecting nothing but out-of-the-way things to happen, that it seemed quite dull and stupid for life to go on in the common way.\n",
      "\n",
      "So she set to work, and very soon finished off the cake.\n"
     ]
    }
   ],
   "source": [
    "print(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa644d7",
   "metadata": {
    "id": "TiCwKJ_VbKq3",
    "papermill": {
     "duration": 0.049915,
     "end_time": "2023-02-23T00:58:19.175043",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.125128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting lines and finding words\n",
    "\n",
    "We can split the text into separate lines using splitlines() method. \n",
    "- Since there are lot of lines, we'll only print the first 5 of them by appending `[:5]` to the name of the variable contianing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7d4102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:19.262123Z",
     "iopub.status.busy": "2023-02-23T00:58:19.261249Z",
     "iopub.status.idle": "2023-02-23T00:58:19.270035Z",
     "shell.execute_reply": "2023-02-23T00:58:19.269097Z"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1677006555810,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "aLyhzsTQbKq3",
    "outputId": "7aa53c8b-2317-49d4-df61-c8ea3dc289f6",
    "papermill": {
     "duration": 0.053975,
     "end_time": "2023-02-23T00:58:19.272385",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.218410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\",\n",
       " 'So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.',\n",
       " '',\n",
       " \"There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, `Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\",\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = doc2.splitlines()\n",
    "lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1cdea9",
   "metadata": {
    "id": "a8AFF-WibKq4",
    "papermill": {
     "duration": 0.039551,
     "end_time": "2023-02-23T00:58:19.349376",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.309825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that: \n",
    "- Some of the lines contain no text at all.\n",
    "- Some of the lines are surrounded by the double quote character \" becuase they contain the single quote character in the text. \n",
    "\n",
    "How many lines are there in total in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9685817c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:19.425897Z",
     "iopub.status.busy": "2023-02-23T00:58:19.425103Z",
     "iopub.status.idle": "2023-02-23T00:58:19.432314Z",
     "shell.execute_reply": "2023-02-23T00:58:19.431185Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006560090,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "NfWU5HQhbKq4",
    "outputId": "bafe1780-5a05-47e6-f3e3-b7e91d901f72",
    "papermill": {
     "duration": 0.048338,
     "end_time": "2023-02-23T00:58:19.434653",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.386315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87207012",
   "metadata": {
    "id": "sD9FbeMnbKq4",
    "papermill": {
     "duration": 0.036737,
     "end_time": "2023-02-23T00:58:19.508161",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.471424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can search for a particular word in the text: \n",
    "- For example, let's search for the word 'Rabbit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6642d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:19.584129Z",
     "iopub.status.busy": "2023-02-23T00:58:19.583268Z",
     "iopub.status.idle": "2023-02-23T00:58:19.591940Z",
     "shell.execute_reply": "2023-02-23T00:58:19.590667Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006560665,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "oRAD91wXbKq4",
    "outputId": "ece6f2fb-20a8-42fe-b1e1-7c43863d990b",
    "papermill": {
     "duration": 0.050327,
     "end_time": "2023-02-23T00:58:19.595267",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.544940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.find('Rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c4001",
   "metadata": {
    "id": "WZCPevxbbKq4",
    "papermill": {
     "duration": 0.041859,
     "end_time": "2023-02-23T00:58:19.681438",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.639579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The number tells us that the word appears at the 552nd character position. \n",
    "\n",
    "We can format the output to state this explicitly:\n",
    "- We use the '+' command to concatenate strings, \n",
    "- and the str() command for converting an integer to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5fce19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:19.759164Z",
     "iopub.status.busy": "2023-02-23T00:58:19.758249Z",
     "iopub.status.idle": "2023-02-23T00:58:19.765612Z",
     "shell.execute_reply": "2023-02-23T00:58:19.764090Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006562735,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "6yT6aWipbKq4",
    "outputId": "94ddbf34-9d80-45ab-c00d-44ebf34912b4",
    "papermill": {
     "duration": 0.048448,
     "end_time": "2023-02-23T00:58:19.767993",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.719545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'Rabbit' appeared at character position 552in the text\n"
     ]
    }
   ],
   "source": [
    "word = \"Rabbit\"\n",
    "mystring = f\"The word '{word}' appeared at character position {str(doc2.find(word))}in the text\"\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b007bd0",
   "metadata": {
    "id": "j34S1khxpIH3",
    "papermill": {
     "duration": 0.03672,
     "end_time": "2023-02-23T00:58:19.843616",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.806896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What happens if we search for a string that does't exist in the document? \n",
    "- Try it... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b91974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:19.921954Z",
     "iopub.status.busy": "2023-02-23T00:58:19.921180Z",
     "iopub.status.idle": "2023-02-23T00:58:19.926983Z",
     "shell.execute_reply": "2023-02-23T00:58:19.926086Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006568329,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "LCrROJ69pCa_",
    "papermill": {
     "duration": 0.048071,
     "end_time": "2023-02-23T00:58:19.929379",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.881308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "doc2.find(\"sanjay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfced5",
   "metadata": {
    "id": "7_1gK8GIbKq5",
    "papermill": {
     "duration": 0.037429,
     "end_time": "2023-02-23T00:58:20.004724",
     "exception": false,
     "start_time": "2023-02-23T00:58:19.967295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Investigating the vocabulary of a document\n",
    "\n",
    "Now let's find the vocabulary of this text by: \n",
    "- first converting the text to lowercase\n",
    "- then splitting the words on whitespace\n",
    "- then selecting only distinct words by using the set() function\n",
    "\n",
    "Python sets are just regular sets from math where you can put heterogenous variables, only a single copy of each element is allowed in a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa693b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:20.081795Z",
     "iopub.status.busy": "2023-02-23T00:58:20.081063Z",
     "iopub.status.idle": "2023-02-23T00:58:20.087305Z",
     "shell.execute_reply": "2023-02-23T00:58:20.086273Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006569627,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "5zkUbepNbKq5",
    "outputId": "62db7d12-b8f6-4eef-a56b-c3032e368dab",
    "papermill": {
     "duration": 0.047602,
     "end_time": "2023-02-23T00:58:20.089670",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.042068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'telescope!', 'label,', 'fountains,', 'word)', 'legs', 'work,', \"house!'\", \"time?'\", 'tired', \"ma'am,\", 'maps', \"marmalade',\", 'straight', 'taste', 'nice', 'printed', 'afraid,', 'as,', 'pictures', 'deep,', \"it'll\", 'seen', 'feet,', 'because', '`now,', \"alice's\", 'if', 'afterwards,', 'fear', 'wild', 'eyes', 'longer', 'as', '(for,', '`--yes,', 'pleasure', 'asking!', 'else', 'glass;', 'ran', 'alas!', 'ask', 'had,', 'saw', 'stupid', 'hedge.', 'some', 'still', 'leaves,', 'table:', 'read', 'ate', '`i', 'poor', 'ears', 'might', 'is', 'presently', '(alice', 'started', 'feel', 'several', 'here', 'out', 'curtsey', 'three-legged', 'sight,', 'long;', 'led', '`to', 'common', 'people!', \"first,'\", 'said,', 'door,', 'near', '`--but', 'large', 'round', 'ought', 'one', 'out,', 'funny', 'soon', 'eat', 'too', 'but', '(`which', 'plainly', 'find', 'behind', 'saying', 'small,', 'size', '(she', 'really', 'at', 'looked', 'dreamy', 'things,', 'larger,', 'jar', \"minute!'\", 'made', 'talking', 'say.)', 'solid', 'alas', 'walked', 'followed', 'cats', 'saucer', 'glass,', 'fifteen', \"book,'\", 'plenty', 'matter', 'finished', 'minutes', 'hurry.', 'fond', 'roast', 'nice,', '`come,', 'way.', 'to', 'picking', '`drink', 'curious', 'paper', 'bit', 'bleeds;', 'seldom', '`in', 'than', 'managed', 'hurried', '`orange', 'it),', 'knowledge,', 'itself,', 'herself', '`what', 'earth.', 'toast,)', 'her', 'size:', 'down.', 'stairs!', 'my', 'flame', 'severely', \"i've\", 'fitted!', 'manage', \"you're\", 'high,', 'friends', 'bright', \"happens!'\", 'waiting', 'passage,', 'surprised', 'sure,', 'fact,', 'oh', \"late!'\", 'top', 'make', 'certain', 'left', 'letters.', 'bring', 'look', 'dream', 'be', \"way?',\", 'happen,', 'will', 'high:', 'an', 'overhead;', 'time,', 'eye', 'labelled', 'children', 'sleepy', 'good', 'pop', 'it?)', 'eaten', 'sort', 'long,', 'down', 'girl', 'wondering', 'came', 'after', 'shut', 'country', 'reach', 'except', 'jumped', 'let', 'mice', 'first', 'empty:', 'currants.', 'must', 'idea', '`eat', 'alice,)', 'did', 'respectable', 'face', 'tiny', 'key;', '(it', 'key', 'by', 'there', 'see', 'cherry-tart,', 'sound', 'sometimes,', 'simple', 'loveliest', 'hear', 'many', 'please,', 'was,', 'just', 'saw.', \"i'll\", 'passed;', 'brave', 'beasts', 'miss', 'day', 'slippery;', 'fortunately', \"telescope.'\", 'killing', 'up,', 'histories', '`no,', 'to,', 'began', 'on,', 'beautifully', \"wonder?'\", 'happens', 'very', 'they', 'latitude', 'new', 'found', 'moment:', 'dry', 'sleepy,', 'sticks', 'deep', 'you,', 'lovely', 'more', 'poker', 'cheated', 'zealand', 'set', 'tunnel', 'bats,', 'book-shelves;', 'wise', 'once;', 'ten', \"think--'\", 'hand', \"now,'\", 'seem', 'inches', 'nervous', 'had', 'thousand', 'dark', 'peeped', 'take', 'alice,', 'curtain', 'curtseying', 'makes', 'do,', 'wish', 'disagree', 'people', 'finger', 'end!', 'me!', 'on', \"`poison,'\", 'that', 'under', 'off,', 'shall', 'garden', \"bats?'\", 'listening,', 'sometimes', 'over', 'door', 'toffee,', 'know.', 'expecting', 'bank,', \"conversation?'\", 'practice', 'generally', 'natural);', 'schoolroom,', 'pretending', 'ventured', 'see,', \"getting!'\", 'key,', 'later.', 'cut', 'lessons', 'the', 'should', 'answer', 'mouse,', 'larger', 'much', 'again.', 'buttered', \"don't\", 'likely', \"not';\", 'so', 'own', 'said', 'then', 'right', 'those', 'her.', 'milk', 'heap', 'rat-hole:', 'happened', 'pretend', 'with', 'getting', 'indeed', 'lost:', 'trouble', \"it's\", 'for,', 'flavour', 'alice;', 'say', 'world', 'few', 'opportunity', 'well,', 'air!', 'custard,', 'bats', 'them:', 'filled', 'such', 'pine-apple,', 'thing', 'dull', \"i'm\", 'people.', 'second', 'alice!', 'grand', 'locked;', 'round,', 'shelves', 'rules', \"before,'\", 'nor', '(when', 'glass', 'knife,', 'eats', 'among', 'gave', 'thought', '`it', 'me', 'leave', 'was', 'burning', 'antipathies,', 'other', 'indeed:', 'hold', 'whiskers,', 'late', 'downward!', 'showing', 'away', 'way?', 'mixed', 'rather', 'corner,', 'down,', 'which', 'get', 'them.', 'lamps', 'passage', 'walking', 'could,', 'making', 'doors', 'would', 'great', 'trying', 'blown', 'think', '`but', 'doorway;', 'same', 'coming', 'before', 'her,', 'remained', 'cried.', '`without', 'remembered', 'almost', 'roof.', \"then?'\", 'happened,', \"`well!'\", 'glad', 'delight', 'off', 'that;', \"that's\", 'all', 'mind', 'from', 'through', 'reading,', 'either,', 'alice', 'open', 'garden.', 'this,', 'got', '`well,', 'tell', 'possibly', 'this', 'over)', 'tea-time.', 'sat', 'do:', 'even', 'once', 'seemed', 'knelt', \"`dinah'll\", 'up', 'fell', 'tried', 'best', 'wondered', 'hot', 'went', 'dinah,', 'words', 'locks', 'taught', 'anything;', 'now', 'door;', 'lying', 'of', 'hall,', \"there's\", 'little', 'say,', 'that,', '(as', 'you', 'quite', 'any', 'table,', 'put', 'ignorant', 'or', 'nothing', 'stupid),', 'small', 'white', 'sides', 'middle,', 'how', 'close', 'for', 'lock,', 'about', 'hanging', 'name', \"begin.'\", 'grow', 'pink', '(though', 'like', 'herself,', 'their', 'usually', 'further:', 'see:', \"know,'\", 'across', '`and', 'hung', 'hoping', 'going', 'rabbit', 'before,', 'first,', 'it.', 'drop', 'spoke--fancy', 'trying,', 'actually', 'longed', '`do', 'seen:', 'ever', 'happen', \"they'll\", 'turned', 'your', 'thing.', 'either', 'heads', 'back', 'written', 'use', 'shrink', 'stopping', 'tumbling', 'against', 'flashed', 'tears', 'growing,', 'drink', 'pegs.', 'somebody,', 'while,', 'cupboards', 'unpleasant', 'come', 'over.', 'rabbit-hole', 'daisies,', 'side', 'cool', 'know', 'home!', 'row', 'bottle', 'twice', 'why,', 'time', 'slowly,', 'into', 'fallen', 'occurred', 'marked', 'creep', 'dinah', 'shoulders.', 'another', 'who', 'head', \"australia?'\", 'air,', 'been', 'suddenly,', 'is,', 'other,', 'beginning', 'oh,', 'neck', 'child', 'long', 'bit,', 'have', '\"poison\"', 'cake.', 'them', 'this;', 'suddenly', 'earth!', 'listen', 'disappointment', 'waited', 'red-hot', 'box', 'however,', 'advice,', 'belong', 'dipped', 'garden,', 'along', 'go', 'in', 'took', 'eyes;', 'fancy', 'remember', 'fall', 'four', 'wander', 'scolded', 'lit', '(which', 'well', 'not', 'wind,', 'without', 'miles', 'rate', 'impossible.', '`which', \"wouldn't\", 'a', 'perhaps', 'two', 'ask:', 'curiosity,', 'opened', 'hardly', 'it,', 'anything', \"somewhere.'\", 'table', 'noticed', 'hurrying', 'its', '`oh', 'watch', 'never', \"that!'\", 'bat,', 'hope', 'wonder', 'considering', 'though', \"couldn't\", 'sooner', \"think!'\", 'turkey,', 'moment', 'burn', 'climb', 'cat.)', 'hall;', 'centre', 'off.', 'falling', 'way,', 'out-of-the-way', '`after', \"it,'\", 'every', 'but,', 'finding', 'only', 'when', 'distance--but', 'upon', 'thump!', 'smaller,', \"to?'\", 'sitting', 'bats?', 'whether', 'were', 'feet', 'worth', 'waistcoat-pocket,', 'daisy-chain', 'low', 'i', 'are', 'certainly', 'brightened', 'way', \"cats?'\", 'field', '(and', 'dozing', 'altogether,', 'hurt,', 'earnestly,', \"feeling!'\", 'candle', 'next.', 'aloud.', \"she'll\", 'deeply', \"person!'\", 'felt', \"bat?'\", 'truth:', 'sister', 'catch', 'true.)', 'question,', 'life', 'learnt', 'end,', \"me'\", 'large,', 'care', 'playing', 'dear!', 'to-night,', '`for', 'begun', 'no,', 'flowers', 'telescopes:', \"me,'\", '(dinah', 'and', 'candle.', 'enough', 'advise', 'conversations', 'croquet', 'she', 'it:', 'golden', 'decided', 'well.', 'having', 'walk', 'could', 'sharply;', 'burnt,', 'do', 'forgotten', 'cake,', 'it', 'no', 'lately,', 'remarkable', \"didn't\", \"through,'\", 'anxiously', 'holding', 'crying', 'can', 'things', 'beds', 'past', 'what', 'sadly', 'game', 'longitude', 'book', 'half', 'somewhere', 'shutting'}\n"
     ]
    }
   ],
   "source": [
    "lowercase_doc = doc2.lower()\n",
    "words = lowercase_doc.split()\n",
    "vocab = set(words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ecacd",
   "metadata": {
    "id": "FLXC6_vLbKq5",
    "papermill": {
     "duration": 0.037754,
     "end_time": "2023-02-23T00:58:20.167130",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.129376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To make it easier to read, we could sort the vocabulary alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4010690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:20.246098Z",
     "iopub.status.busy": "2023-02-23T00:58:20.245353Z",
     "iopub.status.idle": "2023-02-23T00:58:20.250900Z",
     "shell.execute_reply": "2023-02-23T00:58:20.250043Z"
    },
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1677006574407,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Pc_XT1nBbKq5",
    "outputId": "ba78e74f-ed04-477b-d79f-d4a23bd1e2cc",
    "papermill": {
     "duration": 0.047546,
     "end_time": "2023-02-23T00:58:20.253032",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.205486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"poison\"', '(`which', '(alice', '(and', '(as', '(dinah', '(for,', '(it', '(she', '(though', '(when', '(which', '`--but', '`--yes,', '`after', '`and', '`but', '`come,', \"`dinah'll\", '`do', '`drink', '`eat', '`for', '`i', '`in', '`it', '`no,', '`now,', '`oh', '`orange', \"`poison,'\", '`to', \"`well!'\", '`well,', '`what', '`which', '`without', 'a', 'about', 'across', 'actually', 'advice,', 'advise', 'afraid,', 'after', 'afterwards,', 'again.', 'against', 'air!', 'air,', 'alas', 'alas!', 'alice', 'alice!', \"alice's\", 'alice,', 'alice,)', 'alice;', 'all', 'almost', 'along', 'aloud.', 'altogether,', 'among', 'an', 'and', 'another', 'answer', 'antipathies,', 'anxiously', 'any', 'anything', 'anything;', 'are', 'as', 'as,', 'ask', 'ask:', 'asking!', 'at', 'ate', \"australia?'\", 'away', 'back', 'bank,', 'bat,', \"bat?'\", 'bats', 'bats,', 'bats?', \"bats?'\", 'be', 'beasts', 'beautifully', 'because', 'beds', 'been', 'before', 'before,', \"before,'\", 'began', \"begin.'\", 'beginning', 'begun', 'behind', 'belong', 'best', 'bit', 'bit,', 'bleeds;', 'blown', 'book', \"book,'\", 'book-shelves;', 'bottle', 'box', 'brave', 'bright', 'brightened', 'bring', 'burn', 'burning', 'burnt,', 'but', 'but,', 'buttered', 'by', 'cake,', 'cake.', 'came', 'can', 'candle', 'candle.', 'care', 'cat.)', 'catch', 'cats', \"cats?'\", 'centre', 'certain', 'certainly', 'cheated', 'cherry-tart,', 'child', 'children', 'climb', 'close', 'come', 'coming', 'common', 'considering', \"conversation?'\", 'conversations', 'cool', 'corner,', 'could', 'could,', \"couldn't\", 'country', 'creep', 'cried.', 'croquet', 'crying', 'cupboards', 'curiosity,', 'curious', 'currants.', 'curtain', 'curtsey', 'curtseying', 'custard,', 'cut', 'daisies,', 'daisy-chain', 'dark', 'day', 'dear!', 'decided', 'deep', 'deep,', 'deeply', 'delight', 'did', \"didn't\", 'dinah', 'dinah,', 'dipped', 'disagree', 'disappointment', 'distance--but', 'do', 'do,', 'do:', \"don't\", 'door', 'door,', 'door;', 'doors', 'doorway;', 'down', 'down,', 'down.', 'downward!', 'dozing', 'dream', 'dreamy', 'drink', 'drop', 'dry', 'dull', 'earnestly,', 'ears', 'earth!', 'earth.', 'eat', 'eaten', 'eats', 'either', 'either,', 'else', 'empty:', 'end!', 'end,', 'enough', 'even', 'ever', 'every', 'except', 'expecting', 'eye', 'eyes', 'eyes;', 'face', 'fact,', 'fall', 'fallen', 'falling', 'fancy', 'fear', 'feel', \"feeling!'\", 'feet', 'feet,', 'fell', 'felt', 'few', 'field', 'fifteen', 'filled', 'find', 'finding', 'finger', 'finished', 'first', 'first,', \"first,'\", 'fitted!', 'flame', 'flashed', 'flavour', 'flowers', 'followed', 'fond', 'for', 'for,', 'forgotten', 'fortunately', 'found', 'fountains,', 'four', 'friends', 'from', 'funny', 'further:', 'game', 'garden', 'garden,', 'garden.', 'gave', 'generally', 'get', 'getting', \"getting!'\", 'girl', 'glad', 'glass', 'glass,', 'glass;', 'go', 'going', 'golden', 'good', 'got', 'grand', 'great', 'grow', 'growing,', 'had', 'had,', 'half', 'hall,', 'hall;', 'hand', 'hanging', 'happen', 'happen,', 'happened', 'happened,', 'happens', \"happens!'\", 'hardly', 'have', 'having', 'head', 'heads', 'heap', 'hear', 'hedge.', 'her', 'her,', 'her.', 'here', 'herself', 'herself,', 'high,', 'high:', 'histories', 'hold', 'holding', 'home!', 'hope', 'hoping', 'hot', \"house!'\", 'how', 'however,', 'hung', 'hurried', 'hurry.', 'hurrying', 'hurt,', 'i', \"i'll\", \"i'm\", \"i've\", 'idea', 'if', 'ignorant', 'impossible.', 'in', 'inches', 'indeed', 'indeed:', 'into', 'is', 'is,', 'it', \"it'll\", \"it's\", 'it),', 'it,', \"it,'\", 'it.', 'it:', 'it?)', 'its', 'itself,', 'jar', 'jumped', 'just', 'key', 'key,', 'key;', 'killing', 'knelt', 'knife,', 'know', \"know,'\", 'know.', 'knowledge,', 'label,', 'labelled', 'lamps', 'large', 'large,', 'larger', 'larger,', 'late', \"late!'\", 'lately,', 'later.', 'latitude', 'learnt', 'leave', 'leaves,', 'led', 'left', 'legs', 'lessons', 'let', 'letters.', 'life', 'like', 'likely', 'listen', 'listening,', 'lit', 'little', 'lock,', 'locked;', 'locks', 'long', 'long,', 'long;', 'longed', 'longer', 'longitude', 'look', 'looked', 'lost:', 'loveliest', 'lovely', 'low', 'lying', \"ma'am,\", 'made', 'make', 'makes', 'making', 'manage', 'managed', 'many', 'maps', 'marked', \"marmalade',\", 'matter', 'me', 'me!', \"me'\", \"me,'\", 'mice', 'middle,', 'might', 'miles', 'milk', 'mind', \"minute!'\", 'minutes', 'miss', 'mixed', 'moment', 'moment:', 'more', 'mouse,', 'much', 'must', 'my', 'name', 'natural);', 'near', 'neck', 'nervous', 'never', 'new', 'next.', 'nice', 'nice,', 'no', 'no,', 'nor', 'not', \"not';\", 'nothing', 'noticed', 'now', \"now,'\", 'occurred', 'of', 'off', 'off,', 'off.', 'oh', 'oh,', 'on', 'on,', 'once', 'once;', 'one', 'only', 'open', 'opened', 'opportunity', 'or', 'other', 'other,', 'ought', 'out', 'out,', 'out-of-the-way', 'over', 'over)', 'over.', 'overhead;', 'own', 'paper', 'passage', 'passage,', 'passed;', 'past', 'peeped', 'pegs.', 'people', 'people!', 'people.', 'perhaps', \"person!'\", 'picking', 'pictures', 'pine-apple,', 'pink', 'plainly', 'playing', 'please,', 'pleasure', 'plenty', 'poker', 'poor', 'pop', 'possibly', 'practice', 'presently', 'pretend', 'pretending', 'printed', 'put', 'question,', 'quite', 'rabbit', 'rabbit-hole', 'ran', 'rat-hole:', 'rate', 'rather', 'reach', 'read', 'reading,', 'really', 'red-hot', 'remained', 'remarkable', 'remember', 'remembered', 'respectable', 'right', 'roast', 'roof.', 'round', 'round,', 'row', 'rules', 'sadly', 'said', 'said,', 'same', 'sat', 'saucer', 'saw', 'saw.', 'say', 'say,', 'say.)', 'saying', 'schoolroom,', 'scolded', 'second', 'see', 'see,', 'see:', 'seem', 'seemed', 'seen', 'seen:', 'seldom', 'set', 'several', 'severely', 'shall', 'sharply;', 'she', \"she'll\", 'shelves', 'should', 'shoulders.', 'showing', 'shrink', 'shut', 'shutting', 'side', 'sides', 'sight,', 'simple', 'sister', 'sitting', 'size', 'size:', 'sleepy', 'sleepy,', 'slippery;', 'slowly,', 'small', 'small,', 'smaller,', 'so', 'solid', 'some', 'somebody,', 'sometimes', 'sometimes,', 'somewhere', \"somewhere.'\", 'soon', 'sooner', 'sort', 'sound', 'spoke--fancy', 'stairs!', 'started', 'sticks', 'still', 'stopping', 'straight', 'stupid', 'stupid),', 'such', 'suddenly', 'suddenly,', 'sure,', 'surprised', 'table', 'table,', 'table:', 'take', 'talking', 'taste', 'taught', 'tea-time.', 'tears', 'telescope!', \"telescope.'\", 'telescopes:', 'tell', 'ten', 'than', 'that', \"that!'\", \"that's\", 'that,', 'that;', 'the', 'their', 'them', 'them.', 'them:', 'then', \"then?'\", 'there', \"there's\", 'they', \"they'll\", 'thing', 'thing.', 'things', 'things,', 'think', \"think!'\", \"think--'\", 'this', 'this,', 'this;', 'those', 'though', 'thought', 'thousand', 'three-legged', 'through', \"through,'\", 'thump!', 'time', 'time,', \"time?'\", 'tiny', 'tired', 'to', 'to,', 'to-night,', \"to?'\", 'toast,)', 'toffee,', 'too', 'took', 'top', 'tried', 'trouble', 'true.)', 'truth:', 'trying', 'trying,', 'tumbling', 'tunnel', 'turkey,', 'turned', 'twice', 'two', 'under', 'unpleasant', 'up', 'up,', 'upon', 'use', 'usually', 'ventured', 'very', 'waistcoat-pocket,', 'waited', 'waiting', 'walk', 'walked', 'walking', 'wander', 'was', 'was,', 'watch', 'way', 'way,', 'way.', 'way?', \"way?',\", 'well', 'well,', 'well.', 'went', 'were', 'what', 'when', 'whether', 'which', 'while,', 'whiskers,', 'white', 'who', 'why,', 'wild', 'will', 'wind,', 'wise', 'wish', 'with', 'without', 'wonder', \"wonder?'\", 'wondered', 'wondering', 'word)', 'words', 'work,', 'world', 'worth', 'would', \"wouldn't\", 'written', 'you', \"you're\", 'you,', 'your', 'zealand']\n"
     ]
    }
   ],
   "source": [
    "sorted_vocab = sorted(vocab)\n",
    "print(sorted_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24915c",
   "metadata": {
    "id": "M4ZzLRipp5KE",
    "papermill": {
     "duration": 0.037517,
     "end_time": "2023-02-23T00:58:20.328191",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.290674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That looks a bit weird. What are all those bracket '(' characters doing there? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703bbe7",
   "metadata": {
    "id": "DIB-6xDabKq5",
    "papermill": {
     "duration": 0.039972,
     "end_time": "2023-02-23T00:58:20.407645",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.367673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing punctuation with a regular expression\n",
    "\n",
    "Notice that many of the vocabulary terms, particularly those at the start of the list, contain punctuation characters like quotes '\"', brackets '(' and exclamation marks '!'. We'll now see how to remove these puntuation characters:\n",
    "- First get a list of punctuation characters from the 'string' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f87b11f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:20.485671Z",
     "iopub.status.busy": "2023-02-23T00:58:20.484871Z",
     "iopub.status.idle": "2023-02-23T00:58:20.490836Z",
     "shell.execute_reply": "2023-02-23T00:58:20.489926Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677006574726,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "KCFQzseTbKq5",
    "outputId": "2819a6cc-1d7c-4b63-b182-c82994d949a4",
    "papermill": {
     "duration": 0.047698,
     "end_time": "2023-02-23T00:58:20.493256",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.445558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbc602",
   "metadata": {
    "id": "wct3c1EAbKq6",
    "papermill": {
     "duration": 0.037906,
     "end_time": "2023-02-23T00:58:20.569619",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.531713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The list is provided as a single string. To convert it to a list of individual characters, just call the list function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "049e4006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:20.650809Z",
     "iopub.status.busy": "2023-02-23T00:58:20.650018Z",
     "iopub.status.idle": "2023-02-23T00:58:20.658558Z",
     "shell.execute_reply": "2023-02-23T00:58:20.657300Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006578578,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "TW-2BMVjbKq6",
    "outputId": "efff3186-f825-434f-a2af-9e117e327dc6",
    "papermill": {
     "duration": 0.051753,
     "end_time": "2023-02-23T00:58:20.661606",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.609853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62235e14",
   "metadata": {
    "id": "kxnuEuSjbKq6",
    "papermill": {
     "duration": 0.037584,
     "end_time": "2023-02-23T00:58:20.738200",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.700616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice the double backslash character '\\\\\\\\' in the list. This is needed because backslash is used as the escape character. So if we don't put a double backslash, Python will interpret the single backslash as escaping the quote character that follows it.\n",
    "\n",
    "We can create a regular expression that will match any of those puncutation characters by simply surrounding the string of punctuation characters with square brackets: \"[]\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17df5d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:20.832629Z",
     "iopub.status.busy": "2023-02-23T00:58:20.831433Z",
     "iopub.status.idle": "2023-02-23T00:58:20.838456Z",
     "shell.execute_reply": "2023-02-23T00:58:20.837153Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006579176,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "VSb8VgZrbKq6",
    "outputId": "6a192f28-69f9-4088-83da-0efa356798c9",
    "papermill": {
     "duration": 0.059304,
     "end_time": "2023-02-23T00:58:20.840745",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.781441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\n"
     ]
    }
   ],
   "source": [
    "regex = '[' + string.punctuation + ']'\n",
    "print(regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00285fc4",
   "metadata": {
    "id": "yJK_3gYDbKq6",
    "papermill": {
     "duration": 0.039635,
     "end_time": "2023-02-23T00:58:20.926580",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.886945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can use the new punctuation matching regular expression with the sub() command in the *re* (regular expression) libarary to remove the unwanted punctuation.\n",
    "- Note that the sub() routine actually performs a substitution each time it finds a match, but we will simply replace the punctuation character with an empty string: ''\n",
    "- Let's print out the first 1000 characters of the text after removing all punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f155319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:21.005762Z",
     "iopub.status.busy": "2023-02-23T00:58:21.004901Z",
     "iopub.status.idle": "2023-02-23T00:58:21.013659Z",
     "shell.execute_reply": "2023-02-23T00:58:21.012378Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006583038,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "LRYPdI3sbKq7",
    "outputId": "71cdf2c1-425a-4625-acdb-afe179bee72d",
    "papermill": {
     "duration": 0.052087,
     "end_time": "2023-02-23T00:58:21.017132",
     "exception": false,
     "start_time": "2023-02-23T00:58:20.965045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do once or twice she had peeped into the book her sister was reading but it had no pictures or conversations in it and what is the use of a book thought Alice without pictures or conversation\n",
      "So she was considering in her own mind as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making a daisychain would be worth the trouble of getting up and picking the daisies when suddenly a White Rabbit with pink eyes ran close by her\n",
      "\n",
      "There was nothing so very remarkable in that nor did Alice think it so very much out of the way to hear the Rabbit say to itself Oh dear Oh dear I shall be late when she thought it over afterwards it occurred to her that she ought to have wondered at this but at the time it all seemed quite natural but when the Rabbit actually took a watch out of its waistcoatpocket and looked at it and then hurried on Alice started to h\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "doc2_nopunctuation = re.sub(regex,'',doc2)\n",
    "print(doc2_nopunctuation[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3047b5e",
   "metadata": {
    "id": "VDrmqJTbbKq7",
    "papermill": {
     "duration": 0.038379,
     "end_time": "2023-02-23T00:58:21.094480",
     "exception": false,
     "start_time": "2023-02-23T00:58:21.056101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Compare this output with the original text for the first 1000 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8161def8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:21.242191Z",
     "iopub.status.busy": "2023-02-23T00:58:21.241756Z",
     "iopub.status.idle": "2023-02-23T00:58:21.247479Z",
     "shell.execute_reply": "2023-02-23T00:58:21.246222Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677006585753,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "A-7aO0mxbKq7",
    "outputId": "298e3d7d-0c2b-42af-e00f-54642cf752d4",
    "papermill": {
     "duration": 0.117739,
     "end_time": "2023-02-23T00:58:21.250304",
     "exception": false,
     "start_time": "2023-02-23T00:58:21.132565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n",
      "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\n",
      "\n",
      "There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, `Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and th\n"
     ]
    }
   ],
   "source": [
    "print(doc2[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e775cd",
   "metadata": {
    "id": "jBjg-w_pbKq7",
    "papermill": {
     "duration": 0.037786,
     "end_time": "2023-02-23T00:58:21.327580",
     "exception": false,
     "start_time": "2023-02-23T00:58:21.289794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've removed the punctuation, let's generate the sorted vocabulary again, by:\n",
    "- converting to lowercase\n",
    "- splitting on whitespace\n",
    "- select only distinct words\n",
    "- and sorting the words alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9645db7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:21.405654Z",
     "iopub.status.busy": "2023-02-23T00:58:21.404951Z",
     "iopub.status.idle": "2023-02-23T00:58:21.411104Z",
     "shell.execute_reply": "2023-02-23T00:58:21.410174Z"
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1677006590564,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "apHh-4PQbKq7",
    "outputId": "0a4efed4-c101-4ce1-9817-edca893e4309",
    "papermill": {
     "duration": 0.048054,
     "end_time": "2023-02-23T00:58:21.413746",
     "exception": false,
     "start_time": "2023-02-23T00:58:21.365692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'across', 'actually', 'advice', 'advise', 'afraid', 'after', 'afterwards', 'again', 'against', 'air', 'alas', 'alice', 'alices', 'all', 'almost', 'along', 'aloud', 'altogether', 'among', 'an', 'and', 'another', 'answer', 'antipathies', 'anxiously', 'any', 'anything', 'are', 'as', 'ask', 'asking', 'at', 'ate', 'australia', 'away', 'back', 'bank', 'bat', 'bats', 'be', 'beasts', 'beautifully', 'because', 'beds', 'been', 'before', 'began', 'begin', 'beginning', 'begun', 'behind', 'belong', 'best', 'bit', 'bleeds', 'blown', 'book', 'bookshelves', 'bottle', 'box', 'brave', 'bright', 'brightened', 'bring', 'burn', 'burning', 'burnt', 'but', 'buttered', 'by', 'cake', 'came', 'can', 'candle', 'care', 'cat', 'catch', 'cats', 'centre', 'certain', 'certainly', 'cheated', 'cherrytart', 'child', 'children', 'climb', 'close', 'come', 'coming', 'common', 'considering', 'conversation', 'conversations', 'cool', 'corner', 'could', 'couldnt', 'country', 'creep', 'cried', 'croquet', 'crying', 'cupboards', 'curiosity', 'curious', 'currants', 'curtain', 'curtsey', 'curtseying', 'custard', 'cut', 'daisies', 'daisychain', 'dark', 'day', 'dear', 'decided', 'deep', 'deeply', 'delight', 'did', 'didnt', 'dinah', 'dinahll', 'dipped', 'disagree', 'disappointment', 'distancebut', 'do', 'dont', 'door', 'doors', 'doorway', 'down', 'downward', 'dozing', 'dream', 'dreamy', 'drink', 'drop', 'dry', 'dull', 'earnestly', 'ears', 'earth', 'eat', 'eaten', 'eats', 'either', 'else', 'empty', 'end', 'enough', 'even', 'ever', 'every', 'except', 'expecting', 'eye', 'eyes', 'face', 'fact', 'fall', 'fallen', 'falling', 'fancy', 'fear', 'feel', 'feeling', 'feet', 'fell', 'felt', 'few', 'field', 'fifteen', 'filled', 'find', 'finding', 'finger', 'finished', 'first', 'fitted', 'flame', 'flashed', 'flavour', 'flowers', 'followed', 'fond', 'for', 'forgotten', 'fortunately', 'found', 'fountains', 'four', 'friends', 'from', 'funny', 'further', 'game', 'garden', 'gave', 'generally', 'get', 'getting', 'girl', 'glad', 'glass', 'go', 'going', 'golden', 'good', 'got', 'grand', 'great', 'grow', 'growing', 'had', 'half', 'hall', 'hand', 'hanging', 'happen', 'happened', 'happens', 'hardly', 'have', 'having', 'head', 'heads', 'heap', 'hear', 'hedge', 'her', 'here', 'herself', 'high', 'histories', 'hold', 'holding', 'home', 'hope', 'hoping', 'hot', 'house', 'how', 'however', 'hung', 'hurried', 'hurry', 'hurrying', 'hurt', 'i', 'idea', 'if', 'ignorant', 'ill', 'im', 'impossible', 'in', 'inches', 'indeed', 'into', 'is', 'it', 'itll', 'its', 'itself', 'ive', 'jar', 'jumped', 'just', 'key', 'killing', 'knelt', 'knife', 'know', 'knowledge', 'label', 'labelled', 'lamps', 'large', 'larger', 'late', 'lately', 'later', 'latitude', 'learnt', 'leave', 'leaves', 'led', 'left', 'legs', 'lessons', 'let', 'letters', 'life', 'like', 'likely', 'listen', 'listening', 'lit', 'little', 'lock', 'locked', 'locks', 'long', 'longed', 'longer', 'longitude', 'look', 'looked', 'lost', 'loveliest', 'lovely', 'low', 'lying', 'maam', 'made', 'make', 'makes', 'making', 'manage', 'managed', 'many', 'maps', 'marked', 'marmalade', 'matter', 'me', 'mice', 'middle', 'might', 'miles', 'milk', 'mind', 'minute', 'minutes', 'miss', 'mixed', 'moment', 'more', 'mouse', 'much', 'must', 'my', 'name', 'natural', 'near', 'neck', 'nervous', 'never', 'new', 'next', 'nice', 'no', 'nor', 'not', 'nothing', 'noticed', 'now', 'occurred', 'of', 'off', 'oh', 'on', 'once', 'one', 'only', 'open', 'opened', 'opportunity', 'or', 'orange', 'other', 'ought', 'out', 'outoftheway', 'over', 'overhead', 'own', 'paper', 'passage', 'passed', 'past', 'peeped', 'pegs', 'people', 'perhaps', 'person', 'picking', 'pictures', 'pineapple', 'pink', 'plainly', 'playing', 'please', 'pleasure', 'plenty', 'poison', 'poker', 'poor', 'pop', 'possibly', 'practice', 'presently', 'pretend', 'pretending', 'printed', 'put', 'question', 'quite', 'rabbit', 'rabbithole', 'ran', 'rate', 'rather', 'rathole', 'reach', 'read', 'reading', 'really', 'redhot', 'remained', 'remarkable', 'remember', 'remembered', 'respectable', 'right', 'roast', 'roof', 'round', 'row', 'rules', 'sadly', 'said', 'same', 'sat', 'saucer', 'saw', 'say', 'saying', 'schoolroom', 'scolded', 'second', 'see', 'seem', 'seemed', 'seen', 'seldom', 'set', 'several', 'severely', 'shall', 'sharply', 'she', 'shell', 'shelves', 'should', 'shoulders', 'showing', 'shrink', 'shut', 'shutting', 'side', 'sides', 'sight', 'simple', 'sister', 'sitting', 'size', 'sleepy', 'slippery', 'slowly', 'small', 'smaller', 'so', 'solid', 'some', 'somebody', 'sometimes', 'somewhere', 'soon', 'sooner', 'sort', 'sound', 'spokefancy', 'stairs', 'started', 'sticks', 'still', 'stopping', 'straight', 'stupid', 'such', 'suddenly', 'sure', 'surprised', 'table', 'take', 'talking', 'taste', 'taught', 'tears', 'teatime', 'telescope', 'telescopes', 'tell', 'ten', 'than', 'that', 'thats', 'the', 'their', 'them', 'then', 'there', 'theres', 'they', 'theyll', 'thing', 'things', 'think', 'this', 'those', 'though', 'thought', 'thousand', 'threelegged', 'through', 'thump', 'time', 'tiny', 'tired', 'to', 'toast', 'toffee', 'tonight', 'too', 'took', 'top', 'tried', 'trouble', 'true', 'truth', 'trying', 'tumbling', 'tunnel', 'turkey', 'turned', 'twice', 'two', 'under', 'unpleasant', 'up', 'upon', 'use', 'usually', 'ventured', 'very', 'waistcoatpocket', 'waited', 'waiting', 'walk', 'walked', 'walking', 'wander', 'was', 'watch', 'way', 'well', 'went', 'were', 'what', 'when', 'whether', 'which', 'while', 'whiskers', 'white', 'who', 'why', 'wild', 'will', 'wind', 'wise', 'wish', 'with', 'without', 'wonder', 'wondered', 'wondering', 'word', 'words', 'work', 'world', 'worth', 'would', 'wouldnt', 'written', 'yes', 'you', 'your', 'youre', 'zealand']\n"
     ]
    }
   ],
   "source": [
    "words = doc2_nopunctuation.lower().split()\n",
    "sorted_vocab = sorted(set(words))\n",
    "print(sorted_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df9beea",
   "metadata": {
    "id": "aY6icNSJbKq7",
    "papermill": {
     "duration": 0.038028,
     "end_time": "2023-02-23T00:58:21.491323",
     "exception": false,
     "start_time": "2023-02-23T00:58:21.453295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Counting term frequencies\n",
    "\n",
    "We often represent documents by their vocbulary, and in particular by their most frequently occuring terms, since those words are most likely to describe well the topic of the document.\n",
    "- We can count the frequency of the terms in the document using the Counter() function from the NLTK (Natural Language Tool Kit) library. \n",
    "- A online book describing the functionality that the NLTK library provides is available here: http://www.nltk.org/book/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8572ce74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:21.570168Z",
     "iopub.status.busy": "2023-02-23T00:58:21.569528Z",
     "iopub.status.idle": "2023-02-23T00:58:23.167097Z",
     "shell.execute_reply": "2023-02-23T00:58:23.165276Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677006590565,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "oJQwv6TpbKq8",
    "outputId": "3696b376-125e-453b-85d6-575c36ea187f",
    "papermill": {
     "duration": 1.64047,
     "end_time": "2023-02-23T00:58:23.170129",
     "exception": false,
     "start_time": "2023-02-23T00:58:21.529659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 89, 'she': 79, 'to': 74, 'and': 65, 'it': 62, 'was': 53, 'a': 52, 'of': 41, 'i': 29, 'alice': 27, 'her': 26, 'in': 26, 'that': 25, 'very': 23, 'down': 22, 'but': 21, 'for': 21, 'had': 20, 'you': 18, 'not': 16, 'on': 15, 'little': 15, 'so': 14, 'as': 14, 'be': 13, 'this': 13, 'herself': 13, 'or': 12, 'up': 12, 'me': 12, 'no': 11, 'with': 11, 'think': 11, 'out': 11, 'way': 11, 'at': 11, 'like': 11, 'what': 10, 'when': 10, 'there': 10, 'all': 10, 'see': 10, 'if': 10, 'do': 9, 'into': 9, 'how': 9, 'one': 9, 'which': 9, 'thought': 8, 'could': 8, 'time': 8, 'about': 8, 'were': 8, 'said': 8, 'get': 7, 'nothing': 7, 'well': 7, 'would': 7, 'went': 7, 'found': 7, 'eat': 7, 'door': 7, 'by': 6, 'is': 6, 'rabbit': 6, 'much': 6, 'say': 6, 'either': 6, 'wonder': 6, 'going': 6, 'off': 6, 'key': 6, 'use': 5, 'suddenly': 5, 'shall': 5, 'then': 5, 'never': 5, 'before': 5, 'after': 5, 'tried': 5, 'too': 5, 'things': 5, 'through': 5, 'my': 5, 'table': 5, 'once': 4, 'oh': 4, 'quite': 4, 'its': 4, 'looked': 4, 'moment': 4, 'again': 4, 'fell': 4, 'first': 4, 'they': 4, 'here': 4, 'upon': 4, 'fall': 4, 'right': 4, 'got': 4, 'people': 4, 'know': 4, 'soon': 4, 'dinah': 4, 'might': 4, 'cats': 4, 'bats': 4, 'now': 4, 'ever': 4, 'hall': 4, 'any': 4, 'garden': 4, 'poor': 4, 'bottle': 4, 'marked': 4, 'having': 3, 'book': 3, 'pictures': 3, 'getting': 3, 'did': 3, 'dear': 3, 'over': 3, 'seemed': 3, 'seen': 3, 'just': 3, 'large': 3, 'under': 3, 'another': 3, 'look': 3, 'dark': 3, 'from': 3, 'such': 3, 'even': 3, 'come': 3, 'sort': 3, 'though': 3, 'good': 3, 'nice': 3, 'words': 3, 'began': 3, 'rather': 3, 'them': 3, 'remember': 3, 'hand': 3, 'came': 3, 'long': 3, 'passage': 3, 'round': 3, 'trying': 3, 'glass': 3, 'golden': 3, 'small': 3, 'however': 3, 'head': 3, 'drink': 3, 'ill': 3, 'poison': 3, 'candle': 3, 'cake': 3, 'tired': 2, 'sister': 2, 'without': 2, 'considering': 2, 'own': 2, 'mind': 2, 'hot': 2, 'made': 2, 'feel': 2, 'sleepy': 2, 'stupid': 2, 'whether': 2, 'white': 2, 'eyes': 2, 'ran': 2, 'close': 2, 'hear': 2, 'late': 2, 'have': 2, 'took': 2, 'watch': 2, 'waistcoatpocket': 2, 'feet': 2, 'across': 2, 'rabbithole': 2, 'falling': 2, 'deep': 2, 'happen': 2, 'make': 2, 'anything': 2, 'noticed': 2, 'cupboards': 2, 'saw': 2, 'jar': 2, 'great': 2, 'put': 2, 'theyll': 2, 'why': 2, 'top': 2, 'an': 2, 'end': 2, 'many': 2, 'miles': 2, 'ive': 2, 'must': 2, 'somewhere': 2, 'earth': 2, 'several': 2, 'still': 2, 'thats': 2, 'latitude': 2, 'longitude': 2, 'itll': 2, 'among': 2, 'their': 2, 'didnt': 2, 'ask': 2, 'air': 2, 'should': 2, 'wish': 2, 'bat': 2, 'saying': 2, 'sometimes': 2, 'felt': 2, 'begun': 2, 'thump': 2, 'bit': 2, 'turned': 2, 'corner': 2, 'ears': 2, 'behind': 2, 'low': 2, 'doors': 2, 'other': 2, 'alas': 2, 'rate': 2, 'inches': 2, 'high': 2, 'opened': 2, 'larger': 2, 'those': 2, 'go': 2, 'telescope': 2, 'only': 2, 'outoftheway': 2, 'happened': 2, 'few': 2, 'indeed': 2, 'back': 2, 'find': 2, 'rules': 2, 'shutting': 2, 'beautifully': 2, 'forgotten': 2, 'finding': 2, 'finished': 2, 'curious': 2, 'size': 2, 'thing': 2, 'reach': 2, 'theres': 2, 'generally': 2, 'box': 2, 'two': 2, 'makes': 2, 'grow': 2, 'can': 2, 'happens': 2, 'beginning': 1, 'sitting': 1, 'bank': 1, 'twice': 1, 'peeped': 1, 'reading': 1, 'conversations': 1, 'conversation': 1, 'day': 1, 'pleasure': 1, 'making': 1, 'daisychain': 1, 'worth': 1, 'trouble': 1, 'picking': 1, 'daisies': 1, 'pink': 1, 'remarkable': 1, 'nor': 1, 'itself': 1, 'afterwards': 1, 'occurred': 1, 'ought': 1, 'wondered': 1, 'natural': 1, 'actually': 1, 'hurried': 1, 'started': 1, 'flashed': 1, 'take': 1, 'burning': 1, 'curiosity': 1, 'field': 1, 'fortunately': 1, 'pop': 1, 'hedge': 1, 'world': 1, 'straight': 1, 'tunnel': 1, 'some': 1, 'dipped': 1, 'stopping': 1, 'slowly': 1, 'plenty': 1, 'next': 1, 'coming': 1, 'sides': 1, 'filled': 1, 'bookshelves': 1, 'maps': 1, 'hung': 1, 'pegs': 1, 'shelves': 1, 'passed': 1, 'labelled': 1, 'orange': 1, 'marmalade': 1, 'disappointment': 1, 'empty': 1, 'drop': 1, 'fear': 1, 'killing': 1, 'somebody': 1, 'managed': 1, 'past': 1, 'tumbling': 1, 'stairs': 1, 'brave': 1, 'home': 1, 'wouldnt': 1, 'house': 1, 'likely': 1, 'true': 1, 'fallen': 1, 'aloud': 1, 'near': 1, 'centre': 1, 'let': 1, 'four': 1, 'thousand': 1, 'learnt': 1, 'lessons': 1, 'schoolroom': 1, 'opportunity': 1, 'showing': 1, 'knowledge': 1, 'listen': 1, 'practice': 1, 'yes': 1, 'distancebut': 1, 'idea': 1, 'grand': 1, 'presently': 1, 'funny': 1, 'seem': 1, 'walk': 1, 'heads': 1, 'downward': 1, 'antipathies': 1, 'glad': 1, 'listening': 1, 'sound': 1, 'word': 1, 'name': 1, 'country': 1, 'please': 1, 'maam': 1, 'new': 1, 'zealand': 1, 'australia': 1, 'curtsey': 1, 'spokefancy': 1, 'curtseying': 1, 'youre': 1, 'manage': 1, 'ignorant': 1, 'girl': 1, 'shell': 1, 'asking': 1, 'perhaps': 1, 'written': 1, 'else': 1, 'talking': 1, 'dinahll': 1, 'miss': 1, 'tonight': 1, 'cat': 1, 'hope': 1, 'saucer': 1, 'milk': 1, 'teatime': 1, 'are': 1, 'mice': 1, 'im': 1, 'afraid': 1, 'catch': 1, 'mouse': 1, 'dreamy': 1, 'couldnt': 1, 'answer': 1, 'question': 1, 'matter': 1, 'dozing': 1, 'dream': 1, 'walking': 1, 'earnestly': 1, 'tell': 1, 'truth': 1, 'heap': 1, 'sticks': 1, 'dry': 1, 'leaves': 1, 'hurt': 1, 'jumped': 1, 'overhead': 1, 'sight': 1, 'hurrying': 1, 'lost': 1, 'away': 1, 'wind': 1, 'whiskers': 1, 'longer': 1, 'lit': 1, 'row': 1, 'lamps': 1, 'hanging': 1, 'roof': 1, 'locked': 1, 'been': 1, 'side': 1, 'every': 1, 'walked': 1, 'sadly': 1, 'middle': 1, 'wondering': 1, 'threelegged': 1, 'solid': 1, 'except': 1, 'tiny': 1, 'alices': 1, 'belong': 1, 'locks': 1, 'open': 1, 'second': 1, 'curtain': 1, 'fifteen': 1, 'lock': 1, 'delight': 1, 'fitted': 1, 'led': 1, 'than': 1, 'rathole': 1, 'knelt': 1, 'along': 1, 'loveliest': 1, 'longed': 1, 'wander': 1, 'beds': 1, 'bright': 1, 'flowers': 1, 'cool': 1, 'fountains': 1, 'doorway': 1, 'shoulders': 1, 'shut': 1, 'begin': 1, 'lately': 1, 'really': 1, 'impossible': 1, 'waiting': 1, 'half': 1, 'hoping': 1, 'telescopes': 1, 'certainly': 1, 'neck': 1, 'paper': 1, 'label': 1, 'printed': 1, 'letters': 1, 'wise': 1, 'hurry': 1, 'read': 1, 'histories': 1, 'children': 1, 'who': 1, 'burnt': 1, 'eaten': 1, 'wild': 1, 'beasts': 1, 'unpleasant': 1, 'because': 1, 'simple': 1, 'friends': 1, 'taught': 1, 'redhot': 1, 'poker': 1, 'will': 1, 'burn': 1, 'hold': 1, 'cut': 1, 'your': 1, 'finger': 1, 'deeply': 1, 'knife': 1, 'usually': 1, 'bleeds': 1, 'almost': 1, 'certain': 1, 'disagree': 1, 'sooner': 1, 'later': 1, 'ventured': 1, 'taste': 1, 'fact': 1, 'mixed': 1, 'flavour': 1, 'cherrytart': 1, 'custard': 1, 'pineapple': 1, 'roast': 1, 'turkey': 1, 'toffee': 1, 'buttered': 1, 'toast': 1, 'feeling': 1, 'ten': 1, 'face': 1, 'brightened': 1, 'lovely': 1, 'waited': 1, 'minutes': 1, 'shrink': 1, 'further': 1, 'nervous': 1, 'altogether': 1, 'fancy': 1, 'flame': 1, 'blown': 1, 'while': 1, 'more': 1, 'decided': 1, 'possibly': 1, 'plainly': 1, 'best': 1, 'climb': 1, 'legs': 1, 'slippery': 1, 'sat': 1, 'cried': 1, 'crying': 1, 'sharply': 1, 'advise': 1, 'leave': 1, 'minute': 1, 'gave': 1, 'advice': 1, 'seldom': 1, 'followed': 1, 'scolded': 1, 'severely': 1, 'bring': 1, 'tears': 1, 'remembered': 1, 'cheated': 1, 'game': 1, 'croquet': 1, 'playing': 1, 'against': 1, 'child': 1, 'fond': 1, 'pretending': 1, 'pretend': 1, 'hardly': 1, 'enough': 1, 'left': 1, 'respectable': 1, 'person': 1, 'eye': 1, 'lying': 1, 'currants': 1, 'smaller': 1, 'creep': 1, 'dont': 1, 'care': 1, 'ate': 1, 'anxiously': 1, 'holding': 1, 'growing': 1, 'surprised': 1, 'remained': 1, 'same': 1, 'sure': 1, 'eats': 1, 'expecting': 1, 'dull': 1, 'life': 1, 'common': 1, 'set': 1, 'work': 1})\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "counts = nltk.Counter(words)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c03cbe",
   "metadata": {
    "id": "W7_W-wMMbKq8",
    "papermill": {
     "duration": 0.038109,
     "end_time": "2023-02-23T00:58:23.246787",
     "exception": false,
     "start_time": "2023-02-23T00:58:23.208678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that the words are ordered according to their frequency. \n",
    "\n",
    "Lets display them again, but this time only the top 20, using the most_common() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "909ce576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:23.324900Z",
     "iopub.status.busy": "2023-02-23T00:58:23.324518Z",
     "iopub.status.idle": "2023-02-23T00:58:23.333581Z",
     "shell.execute_reply": "2023-02-23T00:58:23.332215Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677006593713,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "_K5O9Jp7bKq8",
    "outputId": "3d5d91a9-76fb-4f3b-87bf-f696396d30fa",
    "papermill": {
     "duration": 0.051074,
     "end_time": "2023-02-23T00:58:23.335969",
     "exception": false,
     "start_time": "2023-02-23T00:58:23.284895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 89),\n",
       " ('she', 79),\n",
       " ('to', 74),\n",
       " ('and', 65),\n",
       " ('it', 62),\n",
       " ('was', 53),\n",
       " ('a', 52),\n",
       " ('of', 41),\n",
       " ('i', 29),\n",
       " ('alice', 27),\n",
       " ('her', 26),\n",
       " ('in', 26),\n",
       " ('that', 25),\n",
       " ('very', 23),\n",
       " ('down', 22),\n",
       " ('but', 21),\n",
       " ('for', 21),\n",
       " ('had', 20),\n",
       " ('you', 18),\n",
       " ('not', 16)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6e33f",
   "metadata": {
    "id": "CcxV1cjHbKq9",
    "papermill": {
     "duration": 0.038476,
     "end_time": "2023-02-23T00:58:23.413275",
     "exception": false,
     "start_time": "2023-02-23T00:58:23.374799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Filtering Stopwords\n",
    "\n",
    "The most frequent terms: 'the', 'she', 'to', 'and', 'it', 'was', 'a', 'of', and 'i' aren't very interesting or descriptive of the story.\n",
    "- They are in fact frequent across *all documents* in the English language, and thus convey very little (if any) information about the topic of the document.\n",
    "- These terms are referred to as **'stop-words'**, because they can be removed from the description of the document without adversely affecting (indeed usually improving) the performance of a text search engine indexing the document.\n",
    "- The NLTK library contains lists of stop-word for English, Italian and many other languages. Let's print out the stop-word lists for English and Italian.\n",
    "\n",
    "Before we can get the stopword lists we need to download them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f0cc3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:23.492368Z",
     "iopub.status.busy": "2023-02-23T00:58:23.491956Z",
     "iopub.status.idle": "2023-02-23T00:58:23.780758Z",
     "shell.execute_reply": "2023-02-23T00:58:23.779106Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006602535,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "iDz79vDebKq9",
    "outputId": "ca47c109-0f73-4f7c-c5be-9fd45a3060c2",
    "papermill": {
     "duration": 0.331731,
     "end_time": "2023-02-23T00:58:23.783528",
     "exception": false,
     "start_time": "2023-02-23T00:58:23.451797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6649f3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:23.865281Z",
     "iopub.status.busy": "2023-02-23T00:58:23.864837Z",
     "iopub.status.idle": "2023-02-23T00:58:23.873911Z",
     "shell.execute_reply": "2023-02-23T00:58:23.872640Z"
    },
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1677006610695,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "MnWF6C-KbKq9",
    "outputId": "2abf61cc-f49f-401d-ef2a-5fcdd1512257",
    "papermill": {
     "duration": 0.054048,
     "end_time": "2023-02-23T00:58:23.876946",
     "exception": false,
     "start_time": "2023-02-23T00:58:23.822898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English stopwords:\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Italian stopwords:\n",
      "['ad', 'al', 'allo', 'ai', 'agli', 'all', 'agl', 'alla', 'alle', 'con', 'col', 'coi', 'da', 'dal', 'dallo', 'dai', 'dagli', 'dall', 'dagl', 'dalla', 'dalle', 'di', 'del', 'dello', 'dei', 'degli', 'dell', 'degl', 'della', 'delle', 'in', 'nel', 'nello', 'nei', 'negli', 'nell', 'negl', 'nella', 'nelle', 'su', 'sul', 'sullo', 'sui', 'sugli', 'sull', 'sugl', 'sulla', 'sulle', 'per', 'tra', 'contro', 'io', 'tu', 'lui', 'lei', 'noi', 'voi', 'loro', 'mio', 'mia', 'miei', 'mie', 'tuo', 'tua', 'tuoi', 'tue', 'suo', 'sua', 'suoi', 'sue', 'nostro', 'nostra', 'nostri', 'nostre', 'vostro', 'vostra', 'vostri', 'vostre', 'mi', 'ti', 'ci', 'vi', 'lo', 'la', 'li', 'le', 'gli', 'ne', 'il', 'un', 'uno', 'una', 'ma', 'ed', 'se', 'perché', 'anche', 'come', 'dov', 'dove', 'che', 'chi', 'cui', 'non', 'più', 'quale', 'quanto', 'quanti', 'quanta', 'quante', 'quello', 'quelli', 'quella', 'quelle', 'questo', 'questi', 'questa', 'queste', 'si', 'tutto', 'tutti', 'a', 'c', 'e', 'i', 'l', 'o', 'ho', 'hai', 'ha', 'abbiamo', 'avete', 'hanno', 'abbia', 'abbiate', 'abbiano', 'avrò', 'avrai', 'avrà', 'avremo', 'avrete', 'avranno', 'avrei', 'avresti', 'avrebbe', 'avremmo', 'avreste', 'avrebbero', 'avevo', 'avevi', 'aveva', 'avevamo', 'avevate', 'avevano', 'ebbi', 'avesti', 'ebbe', 'avemmo', 'aveste', 'ebbero', 'avessi', 'avesse', 'avessimo', 'avessero', 'avendo', 'avuto', 'avuta', 'avuti', 'avute', 'sono', 'sei', 'è', 'siamo', 'siete', 'sia', 'siate', 'siano', 'sarò', 'sarai', 'sarà', 'saremo', 'sarete', 'saranno', 'sarei', 'saresti', 'sarebbe', 'saremmo', 'sareste', 'sarebbero', 'ero', 'eri', 'era', 'eravamo', 'eravate', 'erano', 'fui', 'fosti', 'fu', 'fummo', 'foste', 'furono', 'fossi', 'fosse', 'fossimo', 'fossero', 'essendo', 'faccio', 'fai', 'facciamo', 'fanno', 'faccia', 'facciate', 'facciano', 'farò', 'farai', 'farà', 'faremo', 'farete', 'faranno', 'farei', 'faresti', 'farebbe', 'faremmo', 'fareste', 'farebbero', 'facevo', 'facevi', 'faceva', 'facevamo', 'facevate', 'facevano', 'feci', 'facesti', 'fece', 'facemmo', 'faceste', 'fecero', 'facessi', 'facesse', 'facessimo', 'facessero', 'facendo', 'sto', 'stai', 'sta', 'stiamo', 'stanno', 'stia', 'stiate', 'stiano', 'starò', 'starai', 'starà', 'staremo', 'starete', 'staranno', 'starei', 'staresti', 'starebbe', 'staremmo', 'stareste', 'starebbero', 'stavo', 'stavi', 'stava', 'stavamo', 'stavate', 'stavano', 'stetti', 'stesti', 'stette', 'stemmo', 'steste', 'stettero', 'stessi', 'stesse', 'stessimo', 'stessero', 'stando']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print('English stopwords:')\n",
    "print(stopwords.words('english'))\n",
    "print()\n",
    "print('Italian stopwords:')\n",
    "print(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31ac90",
   "metadata": {
    "id": "IQ0U8qCnbKq9",
    "papermill": {
     "duration": 0.046625,
     "end_time": "2023-02-23T00:58:23.963651",
     "exception": false,
     "start_time": "2023-02-23T00:58:23.917026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's remove the stop-words from the tokenised text before counting the frequency of the words in the document. \n",
    "- We can easily remove items from a list using some special syntax in Python: **[x for x in list1 if x not in list2]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f70f6cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:24.061783Z",
     "iopub.status.busy": "2023-02-23T00:58:24.061400Z",
     "iopub.status.idle": "2023-02-23T00:58:24.376620Z",
     "shell.execute_reply": "2023-02-23T00:58:24.375388Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006611950,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "qIHOmIwebKq9",
    "outputId": "ac549860-0732-4a3f-ca20-19b057ce2631",
    "papermill": {
     "duration": 0.361874,
     "end_time": "2023-02-23T00:58:24.379168",
     "exception": false,
     "start_time": "2023-02-23T00:58:24.017294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alice', 27),\n",
       " ('little', 15),\n",
       " ('think', 11),\n",
       " ('way', 11),\n",
       " ('like', 11),\n",
       " ('see', 10),\n",
       " ('one', 9),\n",
       " ('thought', 8),\n",
       " ('could', 8),\n",
       " ('time', 8),\n",
       " ('said', 8),\n",
       " ('get', 7),\n",
       " ('nothing', 7),\n",
       " ('well', 7),\n",
       " ('would', 7),\n",
       " ('went', 7),\n",
       " ('found', 7),\n",
       " ('eat', 7),\n",
       " ('door', 7),\n",
       " ('rabbit', 6)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_nostopwords = [w for w in words if w not in stopwords.words('english')]\n",
    "counts_nostopwords = nltk.Counter(words_nostopwords)\n",
    "counts_nostopwords.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4a5ae",
   "metadata": {
    "id": "R24uBJ9VbKq-",
    "papermill": {
     "duration": 0.040397,
     "end_time": "2023-02-23T00:58:24.459152",
     "exception": false,
     "start_time": "2023-02-23T00:58:24.418755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These words look a little bit better ... \n",
    "- The words 'Alice', 'time', 'eat', 'door' and 'rabbit' might be useful for describing the document\n",
    "- but many of the other words, like 'little', 'like', 'could' and 'get', migh not be as useful.\n",
    "\n",
    "\n",
    "To get an even better list of words for describing the document we would need to make use of information about *how common each word is in general in the English language*, since the more common a particular word is, the less likely it is to be useful for describing the document. \n",
    "- More on that later in the course ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b346f",
   "metadata": {
    "id": "Vu-ex9CDbKq-",
    "papermill": {
     "duration": 0.039416,
     "end_time": "2023-02-23T00:58:24.537638",
     "exception": false,
     "start_time": "2023-02-23T00:58:24.498222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Downloading content from the Web\n",
    "\n",
    "One common source of text documents is the Web. Let's now download an article from Wikipedia, and then extract the text from it.\n",
    "\n",
    "First download the HTML page using the urllib library and print out just the first 2000 bytes of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ff7d2fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:24.617603Z",
     "iopub.status.busy": "2023-02-23T00:58:24.617227Z",
     "iopub.status.idle": "2023-02-23T00:58:26.272326Z",
     "shell.execute_reply": "2023-02-23T00:58:26.271087Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006615662,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "u0BJs4iUbKq-",
    "outputId": "ec12bf54-93cf-424f-867a-4fe49fd7cf7f",
    "papermill": {
     "duration": 1.698268,
     "end_time": "2023-02-23T00:58:26.274933",
     "exception": false,
     "start_time": "2023-02-23T00:58:24.576665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-enabled vector-feature-sticky-header-disabled vector-feature-page-tools-disabled vector-feature-page-tools-pinned-disabled vector-feature-main-menu-pinned-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Dune (novel) - Wikipedia</title>\\n<script>document.documentElement.className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-enabled vector-feature-sticky-header-disabled vector-feature-page-tools-disabled vector-feature-page-tools-pinned-disabled vector-feature-main-menu-pinned-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled\";(function(){var cookie=document.cookie.match(/(?:^|; )enwikimwclientprefs=([^;]+)/);if(cookie){var featureName=cookie[1];document.documentElement.className=document.documentElement.className.replace(featureName+\\'-enabled\\',featureName+\\'-disabled\\');}}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"11ea10b7-c38e-475e-a43e-d1d3284ef031\",\\n\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Dune_(novel)\",\"wgTitle\":\"Dune (novel)\",\"wgCurRevisionId\":1140000594,\"wgRevisionId\":1140000594,\"wgArticleId\":71416,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Webarchive template wayback links\",\"Articles with short description\",\"Short description matches Wikidata\",\"Use mdy dates from November 2021\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request  \n",
    "html_doc = urllib.request.urlopen('https://en.wikipedia.org/wiki/Dune_(novel)').read()\n",
    "html_doc[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b256c56",
   "metadata": {
    "id": "DEroaWgRbKq-",
    "papermill": {
     "duration": 0.039041,
     "end_time": "2023-02-23T00:58:26.354523",
     "exception": false,
     "start_time": "2023-02-23T00:58:26.315482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wow, that looks pretty ugly! \n",
    "\n",
    "Let's use another library (called Beautiful Soup) to parse the content of the page. \n",
    "- When printing out the parsed document we will use the prettify() method to indent all the HTML tags so that we can see the structure of the HTML document. (This is called 'pretty printing' in HTML/XML.)\n",
    "- Note that the printed output is very long, so after looking at it, you may want to edit the code to comment out the print line and re-run the cell. \n",
    " - To comment out the last line, simply place a hash character '#' in front of it: #print(parsed_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44c3f05e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:26.435281Z",
     "iopub.status.busy": "2023-02-23T00:58:26.434599Z",
     "iopub.status.idle": "2023-02-23T00:58:26.963428Z",
     "shell.execute_reply": "2023-02-23T00:58:26.962052Z"
    },
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1677006617025,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "0oHjPDNxbKq-",
    "outputId": "16aff0d9-8449-4b9a-c093-54db68bab201",
    "papermill": {
     "duration": 0.572438,
     "end_time": "2023-02-23T00:58:26.966275",
     "exception": false,
     "start_time": "2023-02-23T00:58:26.393837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bs4 as bs  \n",
    "parsed_doc = bs.BeautifulSoup(html_doc,'lxml')\n",
    "#print(parsed_doc.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b4522",
   "metadata": {
    "id": "DniaRHMebKq_",
    "papermill": {
     "duration": 0.038949,
     "end_time": "2023-02-23T00:58:27.044385",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.005436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extracting text from the HTML\n",
    "\n",
    "Now let's extract the text from the HTML page. \n",
    "- First find all paragraph \\<p\\> ... \\</p\\> elements within the HTML page.\n",
    "- The find_all() method returns a list of the elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96481042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:27.125443Z",
     "iopub.status.busy": "2023-02-23T00:58:27.125015Z",
     "iopub.status.idle": "2023-02-23T00:58:27.136675Z",
     "shell.execute_reply": "2023-02-23T00:58:27.135723Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006617026,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Qetw2l_8bKq_",
    "papermill": {
     "duration": 0.055436,
     "end_time": "2023-02-23T00:58:27.138909",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.083473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paragraph_elements = parsed_doc.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d3760",
   "metadata": {
    "id": "GStEGbJrbKq_",
    "papermill": {
     "duration": 0.039109,
     "end_time": "2023-02-23T00:58:27.218928",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.179819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now print out the first of the paragraph elements to see what it looks like:\n",
    "- Note that Python starts counting from zero, not one, so the first element is: paragraph_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9618feaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:27.300215Z",
     "iopub.status.busy": "2023-02-23T00:58:27.299447Z",
     "iopub.status.idle": "2023-02-23T00:58:27.306215Z",
     "shell.execute_reply": "2023-02-23T00:58:27.304580Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006619410,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "chpj_uCTbKq_",
    "outputId": "6fc5d4ec-3181-4c41-dc8c-12ae133e8650",
    "papermill": {
     "duration": 0.051169,
     "end_time": "2023-02-23T00:58:27.309517",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.258348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"mw-empty-elt\">\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "print(paragraph_elements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a90b80",
   "metadata": {
    "id": "j88DzCBDbKq_",
    "papermill": {
     "duration": 0.039154,
     "end_time": "2023-02-23T00:58:27.388798",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.349644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Well that was pretty uninteresting. The first paragraph was empty!\n",
    "- Print out the second paragraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2969974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:27.470718Z",
     "iopub.status.busy": "2023-02-23T00:58:27.469486Z",
     "iopub.status.idle": "2023-02-23T00:58:27.476744Z",
     "shell.execute_reply": "2023-02-23T00:58:27.475104Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006620445,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "uG1QIZ2LbKq_",
    "outputId": "9ca81004-e66d-4b64-d77b-6c0aaa5bc299",
    "papermill": {
     "duration": 0.050701,
     "end_time": "2023-02-23T00:58:27.479215",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.428514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><i><b>Dune</b></i> is a 1965 <a href=\"/wiki/Epic_(genre)\" title=\"Epic (genre)\">epic</a> <a href=\"/wiki/Science_fiction\" title=\"Science fiction\">science fiction</a> novel by American author <a href=\"/wiki/Frank_Herbert\" title=\"Frank Herbert\">Frank Herbert</a>, originally published as two separate serials in <i><a href=\"/wiki/Analog_Science_Fiction_and_Fact\" title=\"Analog Science Fiction and Fact\">Analog</a></i> magazine. It tied with <a href=\"/wiki/Roger_Zelazny\" title=\"Roger Zelazny\">Roger Zelazny</a>'s <i><a href=\"/wiki/This_Immortal\" title=\"This Immortal\">This Immortal</a></i> for the <a href=\"/wiki/Hugo_Award\" title=\"Hugo Award\">Hugo Award</a> in 1966 and it won the inaugural <a href=\"/wiki/Nebula_Award_for_Best_Novel\" title=\"Nebula Award for Best Novel\">Nebula Award for Best Novel</a>. It is the first installment of the <a href=\"/wiki/Dune_(franchise)\" title=\"Dune (franchise)\"><i>Dune</i> saga</a>. In 2003, it was described as the world's best-selling science fiction novel.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "print(paragraph_elements[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c517d",
   "metadata": {
    "id": "MaHrFocybKq_",
    "papermill": {
     "duration": 0.041291,
     "end_time": "2023-02-23T00:58:27.560626",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.519335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "OK, now let's get the text of each paragraph, without all of the HTML markup:\n",
    "- To do that we'll use the same python construct we saw before for iterating over the elements of a list.\n",
    "- This time though, we'll perform an operation on each element (extract the text) before returning the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecff5f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:27.645867Z",
     "iopub.status.busy": "2023-02-23T00:58:27.645144Z",
     "iopub.status.idle": "2023-02-23T00:58:27.651603Z",
     "shell.execute_reply": "2023-02-23T00:58:27.650696Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006621796,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "FZ4e7kyVbKrA",
    "papermill": {
     "duration": 0.051677,
     "end_time": "2023-02-23T00:58:27.653918",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.602241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paragraph_texts = [p.text for p in paragraph_elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9fdb40",
   "metadata": {
    "id": "Vcgx_IwAbKrA",
    "papermill": {
     "duration": 0.040839,
     "end_time": "2023-02-23T00:58:27.736416",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.695577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Print out the second paragraph to see how it looks without all of the HTML tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0911b659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:27.817889Z",
     "iopub.status.busy": "2023-02-23T00:58:27.817455Z",
     "iopub.status.idle": "2023-02-23T00:58:27.822805Z",
     "shell.execute_reply": "2023-02-23T00:58:27.821544Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677006621797,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "cepBdE6ObKrA",
    "outputId": "171cf734-ae4a-4b75-d844-c520cd46c73c",
    "papermill": {
     "duration": 0.049805,
     "end_time": "2023-02-23T00:58:27.826268",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.776463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dune is a 1965 epic science fiction novel by American author Frank Herbert, originally published as two separate serials in Analog magazine. It tied with Roger Zelazny's This Immortal for the Hugo Award in 1966 and it won the inaugural Nebula Award for Best Novel. It is the first installment of the Dune saga. In 2003, it was described as the world's best-selling science fiction novel.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(paragraph_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f143807",
   "metadata": {
    "id": "vSkaGgtxbKrA",
    "papermill": {
     "duration": 0.040216,
     "end_time": "2023-02-23T00:58:27.908509",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.868293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Print out the whole list to see text from the entire document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcfae448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:27.991098Z",
     "iopub.status.busy": "2023-02-23T00:58:27.990664Z",
     "iopub.status.idle": "2023-02-23T00:58:27.995805Z",
     "shell.execute_reply": "2023-02-23T00:58:27.994559Z"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1677006625707,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "O38oIsntbKrA",
    "outputId": "745fe74f-9be5-4ba1-addf-694a57294d73",
    "papermill": {
     "duration": 0.048357,
     "end_time": "2023-02-23T00:58:27.998192",
     "exception": false,
     "start_time": "2023-02-23T00:58:27.949835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(paragraph_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c2022",
   "metadata": {
    "id": "fLVjuK81bKrA",
    "papermill": {
     "duration": 0.038821,
     "end_time": "2023-02-23T00:58:28.076966",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.038145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So there we have it, a list of paragraphs that have been extracted from a webpage.\n",
    "\n",
    "What shall we do with this text? \n",
    "- First let's join all the paragraphs together in a single string, separating them with a newline `\\n` character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd7804a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:28.158564Z",
     "iopub.status.busy": "2023-02-23T00:58:28.158185Z",
     "iopub.status.idle": "2023-02-23T00:58:28.163263Z",
     "shell.execute_reply": "2023-02-23T00:58:28.162031Z"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1677006625707,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "6LqUUP36bKrA",
    "outputId": "f25f3fab-7b3b-4804-84e3-8743d0512235",
    "papermill": {
     "duration": 0.048855,
     "end_time": "2023-02-23T00:58:28.165710",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.116855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_text = '\\n'.join(paragraph_texts)\n",
    "#print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116eb1e7",
   "metadata": {
    "id": "zYoolZfobKrB",
    "papermill": {
     "duration": 0.039279,
     "end_time": "2023-02-23T00:58:28.246307",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.207028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Searching within extracted text\n",
    "\n",
    "Now that we have the text in a convenient format, we can start doing some analysis on the it. \n",
    "- We could search for somebody's name, e.g. the author 'Frank Herbert', by using the `search` command from the regular expression package 're' imported above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8acc4665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:28.331444Z",
     "iopub.status.busy": "2023-02-23T00:58:28.331051Z",
     "iopub.status.idle": "2023-02-23T00:58:28.337477Z",
     "shell.execute_reply": "2023-02-23T00:58:28.336473Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006626049,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "S-kI5ERqbKrB",
    "outputId": "663fb2bd-42c1-40d7-8b47-7c4dad306bd0",
    "papermill": {
     "duration": 0.049383,
     "end_time": "2023-02-23T00:58:28.339595",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.290212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(63, 76), match='Frank Herbert'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('Frank Herbert', complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772929f",
   "metadata": {
    "id": "Da5XgFHObKrB",
    "papermill": {
     "duration": 0.038991,
     "end_time": "2023-02-23T00:58:28.418986",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.379995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This tells us that the author is first mentioned in between characters 256 and 269\n",
    "\n",
    "Let's find out how many times the director has been mentioned in the article. To do that we need to use the `findall()` command rather than search() command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29aa55a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:28.499974Z",
     "iopub.status.busy": "2023-02-23T00:58:28.499561Z",
     "iopub.status.idle": "2023-02-23T00:58:28.505899Z",
     "shell.execute_reply": "2023-02-23T00:58:28.504656Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006626347,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "FlE3ND0bbKrB",
    "outputId": "45989154-18d4-4487-fcf5-e72f69c79f9a",
    "papermill": {
     "duration": 0.050738,
     "end_time": "2023-02-23T00:58:28.509034",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.458296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert', 'Frank Herbert']\n",
      "The name 'Frank Herbert' occurs 18 times\n"
     ]
    }
   ],
   "source": [
    "name = 'Frank Herbert'\n",
    "matches = re.findall(name, complete_text)\n",
    "print(matches)\n",
    "print(f\"The name '{name}' occurs {len(matches)} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39849426",
   "metadata": {
    "id": "eM8y7KHxbKrB",
    "papermill": {
     "duration": 0.03904,
     "end_time": "2023-02-23T00:58:28.588629",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.549589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "More than just knowing that the author is being mentioned, we'd like to know what is being said about him. So we'd like to extract the sentences mentioning him. \n",
    "- We can do that by changing the regular expression that we are using to be more than just a string of keywords.\n",
    "\n",
    "The required regular expression is a little complicated, so let's build up to it slowly. \n",
    "- First let's write a simple expression to capture the first 10 characters immediately after his name. \n",
    "- In regular expressions, the dot character '.' is a wild-card that matches any character\n",
    "- so to match the next 10 characters, we can simply add ten dots to his name: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "730bdfa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:28.670015Z",
     "iopub.status.busy": "2023-02-23T00:58:28.669571Z",
     "iopub.status.idle": "2023-02-23T00:58:28.679414Z",
     "shell.execute_reply": "2023-02-23T00:58:28.677811Z"
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1677006631400,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "06Y1SEXQbKrB",
    "outputId": "5af8203a-ae91-4eda-9110-235240763fea",
    "papermill": {
     "duration": 0.052915,
     "end_time": "2023-02-23T00:58:28.681946",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.629031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression: 'Frank Herbert..........'\n",
      "Returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Frank Herbert, original',\n",
       " \"Frank Herbert's Dune an\",\n",
       " \"Frank Herbert's Childre\",\n",
       " 'Frank Herbert’s classic',\n",
       " 'Frank Herbert drew para',\n",
       " 'Frank Herbert stated th',\n",
       " 'Frank Herbert as depict',\n",
       " 'Frank Herbert said in 1',\n",
       " \"Frank Herbert's fiction\",\n",
       " \"Frank Herbert, O'Reilly\",\n",
       " 'Frank Herbert Archives.',\n",
       " \"Frank Herbert's books.[\",\n",
       " \"Frank Herbert's final n\",\n",
       " 'Frank Herbert traveled ',\n",
       " \"Frank Herbert's. But I \",\n",
       " \"Frank Herbert's Dune, a\",\n",
       " \"Frank Herbert's son Bri\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = name + '..........'\n",
    "print(f\"Regular expression: '{regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db67511",
   "metadata": {
    "id": "PCZs2Aa0bKrB",
    "papermill": {
     "duration": 0.041383,
     "end_time": "2023-02-23T00:58:28.765614",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.724231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That text window is far too short to be useful, and the regular expresssion is also particularly ugly. \n",
    "- Let's simplify regular expression by using the notation: `{n}` to repeat the previous character n times\n",
    "- and extend the window out to 100 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9e4951b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:28.849382Z",
     "iopub.status.busy": "2023-02-23T00:58:28.848913Z",
     "iopub.status.idle": "2023-02-23T00:58:28.857817Z",
     "shell.execute_reply": "2023-02-23T00:58:28.856348Z"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1677006637321,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "frUSbdxabKrB",
    "outputId": "c922bfbd-2c87-434d-8e65-5a149a1be7a6",
    "papermill": {
     "duration": 0.054557,
     "end_time": "2023-02-23T00:58:28.860442",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.805885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression: 'Frank Herbert.{100}'\n",
      "Returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Frank Herbert, originally published as two separate serials in Analog magazine. It tied with Roger Zelazny's This\",\n",
       " \"Frank Herbert's Dune and its 2003 sequel Frank Herbert's Children of Dune (which combines the events of Dune Mess\",\n",
       " 'Frank Herbert’s classic novel is a vast ocean of sand, with giant worms diving into the depths, the mysterious an',\n",
       " 'Frank Herbert drew parallels, used spectacular metaphors, and extrapolated present conditions into world systems ',\n",
       " 'Frank Herbert stated that bureaucracy that lasted long enough would become a hereditary nobility, and a significa',\n",
       " 'Frank Herbert as depicting \"war as a collective orgasm\" (drawing on Norman Walter\\'s 1950 The Sexual Cycle of Huma',\n",
       " 'Frank Herbert said in 1979, \"The bottom line of the Dune trilogy is: beware of heroes. Much better  [to] rely on ',\n",
       " 'Frank Herbert\\'s fictional future in which \"religious beliefs have combined into interesting forms\" represents the',\n",
       " 'Frank Herbert, O\\'Reilly wrote that \"Dune is clearly a commentary on the Foundation trilogy. Herbert has taken a l',\n",
       " \"Frank Herbert's books.[92] The notes for what would have been Dune 7 also enabled them to publish Hunters of Dune\",\n",
       " \"Frank Herbert's final novel Chapterhouse: Dune, which complete the chronological progression of his original seri\",\n",
       " 'Frank Herbert traveled to Europe in 1976 to find that $2 million of the $9.5 million budget had already been spen',\n",
       " \"Frank Herbert's. But I also realised Dune was going to take a lot more work—at least two and a half years' worth.\",\n",
       " \"Frank Herbert's Dune, a miniseries which premiered on American Sci-Fi Channel.[15] As of 2004, the miniseries was\",\n",
       " \"Frank Herbert's son Brian Herbert, who had together written multiple Dune sequels and prequels since 1999, were a\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = name + '.{100}'\n",
    "print(f\"Regular expression: '{regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0b078",
   "metadata": {
    "id": "2ESWmmtAbKrB",
    "papermill": {
     "duration": 0.041055,
     "end_time": "2023-02-23T00:58:28.943314",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.902259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Well the regular expression worked, but we lost one of the results because the required character window was too big. \n",
    "- A newline character was encountered less than 100 characters after the director's name.\n",
    "- To fix this, let's change the number of repetitions to be minimum zero, maximum 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18fc29b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:29.025736Z",
     "iopub.status.busy": "2023-02-23T00:58:29.025293Z",
     "iopub.status.idle": "2023-02-23T00:58:29.033770Z",
     "shell.execute_reply": "2023-02-23T00:58:29.032547Z"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1677006651466,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "zrgXaV_ZbKrC",
    "outputId": "3d2d635b-7d02-476f-e1ef-1b45131914c4",
    "papermill": {
     "duration": 0.0526,
     "end_time": "2023-02-23T00:58:29.036278",
     "exception": false,
     "start_time": "2023-02-23T00:58:28.983678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Frank Herbert, originally published as two separate serials in Analog magazine. It tied with Roger Zelazny's This\",\n",
       " \"Frank Herbert's Dune and its 2003 sequel Frank Herbert's Children of Dune (which combines the events of Dune Mess\",\n",
       " 'Frank Herbert’s classic novel is a vast ocean of sand, with giant worms diving into the depths, the mysterious an',\n",
       " 'Frank Herbert drew parallels, used spectacular metaphors, and extrapolated present conditions into world systems ',\n",
       " 'Frank Herbert stated that bureaucracy that lasted long enough would become a hereditary nobility, and a significa',\n",
       " 'Frank Herbert as depicting \"war as a collective orgasm\" (drawing on Norman Walter\\'s 1950 The Sexual Cycle of Huma',\n",
       " 'Frank Herbert said in 1979, \"The bottom line of the Dune trilogy is: beware of heroes. Much better  [to] rely on ',\n",
       " 'Frank Herbert wrote:',\n",
       " 'Frank Herbert\\'s fictional future in which \"religious beliefs have combined into interesting forms\" represents the',\n",
       " 'Frank Herbert, O\\'Reilly wrote that \"Dune is clearly a commentary on the Foundation trilogy. Herbert has taken a l',\n",
       " 'Frank Herbert Archives.[90]',\n",
       " \"Frank Herbert's books.[92] The notes for what would have been Dune 7 also enabled them to publish Hunters of Dune\",\n",
       " \"Frank Herbert's final novel Chapterhouse: Dune, which complete the chronological progression of his original seri\",\n",
       " 'Frank Herbert traveled to Europe in 1976 to find that $2 million of the $9.5 million budget had already been spen',\n",
       " \"Frank Herbert's. But I also realised Dune was going to take a lot more work—at least two and a half years' worth.\",\n",
       " \"Frank Herbert's Dune, a miniseries which premiered on American Sci-Fi Channel.[15] As of 2004, the miniseries was\",\n",
       " \"Frank Herbert's son Brian Herbert, who had together written multiple Dune sequels and prequels since 1999, were a\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = name + '.{,100}'\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25117c",
   "metadata": {
    "id": "0Rs0jgcPbKrC",
    "papermill": {
     "duration": 0.040972,
     "end_time": "2023-02-23T00:58:29.117780",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.076808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "OK, so that was fun, but what we'd really like to do is get the whole sentence around his name.\n",
    "- To do that we'll have to find all of the characters both before and after his name that do not include the period '.' character. \n",
    "- To choose any character except '.' we can write `[^.]` and to repeat that pattern zero or more times, we simply append '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "059bac3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:29.201320Z",
     "iopub.status.busy": "2023-02-23T00:58:29.200895Z",
     "iopub.status.idle": "2023-02-23T00:58:29.224740Z",
     "shell.execute_reply": "2023-02-23T00:58:29.223607Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677006656181,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "4NOpnAEebKrC",
    "outputId": "8a73ac41-4086-42a9-adb7-f7fdc14ad0e3",
    "papermill": {
     "duration": 0.068626,
     "end_time": "2023-02-23T00:58:29.227289",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.158663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nDune is a 1965 epic science fiction novel by American author Frank Herbert, originally published as two separate serials in Analog magazine',\n",
       " \" The book was also adapted into the 2000 Sci-Fi Channel miniseries Frank Herbert's Dune and its 2003 sequel Frank Herbert's Children of Dune (which combines the events of Dune Messiah and Children of Dune)\",\n",
       " ' The desert of Frank Herbert’s classic novel is a vast ocean of sand, with giant worms diving into the depths, the mysterious and unrevealed domain of Shai-hulud',\n",
       " ' Frank Herbert drew parallels, used spectacular metaphors, and extrapolated present conditions into world systems that seem entirely alien at first blush',\n",
       " '[40] Frank Herbert stated that bureaucracy that lasted long enough would become a hereditary nobility, and a significant theme behind the aristocratic families in Dune was \"aristocratic bureaucracy\" which he saw as analogous to the Soviet Union',\n",
       " '[51]\\n\\nThe decline and long peace of the Empire sets the stage for revolution and renewal by genetic mixing of successful and unsuccessful groups through war, a process culminating in the Jihad led by Paul Atreides, described by Frank Herbert as depicting \"war as a collective orgasm\" (drawing on Norman Walter\\'s 1950 The Sexual Cycle of Human Warfare),[52][53] themes that would reappear in God Emperor of Dune\\'s Scattering and Leto II\\'s all-female Fish Speaker army',\n",
       " ' Author Frank Herbert said in 1979, \"The bottom line of the Dune trilogy is: beware of heroes',\n",
       " '[69] In \"Dune Genesis\", Frank Herbert wrote:\\n\\nWhat especially pleases me is to see the interwoven themes, the fugue like relationships of images that exactly replay the way Dune took shape',\n",
       " '[70] He added that Frank Herbert\\'s fictional future in which \"religious beliefs have combined into interesting forms\" represents the author\\'s solution to eliminating arguments between religions, each of which claimed to have \"the one and only revelation',\n",
       " ' In his monograph on Frank Herbert, O\\'Reilly wrote that \"Dune is clearly a commentary on the Foundation trilogy',\n",
       " \"[89]\\n\\nCalifornia State University, Fullerton's Pollack Library has several of Herbert's draft manuscripts of Dune and other works, with the author's notes, in their Frank Herbert Archives\",\n",
       " \" Brian Herbert's and Anderson's Dune prequels first started publication in 1999, and have led to additional stories that take place between those of Frank Herbert's books\",\n",
       " \"[92] The notes for what would have been Dune 7 also enabled them to publish Hunters of Dune (2006) and Sandworms of Dune (2007), sequels to Frank Herbert's final novel Chapterhouse: Dune, which complete the chronological progression of his original series, and wrap up storylines that began in Heretics of Dune\",\n",
       " ' Frank Herbert traveled to Europe in 1976 to find that $2 million of the $9',\n",
       " \" As he recalls, the pre-production process was slow, and finishing the project would have been even more time-intensive:\\n\\nBut after seven months I dropped out of Dune, by then Rudy Wurlitzer had come up with a first-draft script which I felt was a decent distillation of Frank Herbert's\",\n",
       " \"[105]\\n\\nIn 2000, John Harrison adapted the novel into Frank Herbert's Dune, a miniseries which premiered on American Sci-Fi Channel\",\n",
       " \" Anderson and Frank Herbert's son Brian Herbert, who had together written multiple Dune sequels and prequels since 1999, were attached to the project as technical advisors\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = '[^.]*' + name + '[^.]*'\n",
    "re.findall(regex, complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a4b22",
   "metadata": {
    "id": "beROSLPcbKrC",
    "papermill": {
     "duration": 0.04215,
     "end_time": "2023-02-23T00:58:29.311191",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.269041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, let's clean up the output a little: \n",
    "- by stripping off spaces and newline characters at the start of each sentence using the strip() method\n",
    "- and reappending the missing period at the end with `+ '.'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e335fde0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:29.395055Z",
     "iopub.status.busy": "2023-02-23T00:58:29.394596Z",
     "iopub.status.idle": "2023-02-23T00:58:29.418324Z",
     "shell.execute_reply": "2023-02-23T00:58:29.417510Z"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1677006661455,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "dHg6gew9bKrC",
    "outputId": "3321ca11-9f74-4f81-d260-1884c3ec96dd",
    "papermill": {
     "duration": 0.068227,
     "end_time": "2023-02-23T00:58:29.420704",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.352477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dune is a 1965 epic science fiction novel by American author Frank Herbert, originally published as two separate serials in Analog magazine.',\n",
       " \"The book was also adapted into the 2000 Sci-Fi Channel miniseries Frank Herbert's Dune and its 2003 sequel Frank Herbert's Children of Dune (which combines the events of Dune Messiah and Children of Dune).\",\n",
       " 'The desert of Frank Herbert’s classic novel is a vast ocean of sand, with giant worms diving into the depths, the mysterious and unrevealed domain of Shai-hulud.',\n",
       " 'Frank Herbert drew parallels, used spectacular metaphors, and extrapolated present conditions into world systems that seem entirely alien at first blush.',\n",
       " '[40] Frank Herbert stated that bureaucracy that lasted long enough would become a hereditary nobility, and a significant theme behind the aristocratic families in Dune was \"aristocratic bureaucracy\" which he saw as analogous to the Soviet Union.',\n",
       " '[51]\\n\\nThe decline and long peace of the Empire sets the stage for revolution and renewal by genetic mixing of successful and unsuccessful groups through war, a process culminating in the Jihad led by Paul Atreides, described by Frank Herbert as depicting \"war as a collective orgasm\" (drawing on Norman Walter\\'s 1950 The Sexual Cycle of Human Warfare),[52][53] themes that would reappear in God Emperor of Dune\\'s Scattering and Leto II\\'s all-female Fish Speaker army.',\n",
       " 'Author Frank Herbert said in 1979, \"The bottom line of the Dune trilogy is: beware of heroes.',\n",
       " '[69] In \"Dune Genesis\", Frank Herbert wrote:\\n\\nWhat especially pleases me is to see the interwoven themes, the fugue like relationships of images that exactly replay the way Dune took shape.',\n",
       " '[70] He added that Frank Herbert\\'s fictional future in which \"religious beliefs have combined into interesting forms\" represents the author\\'s solution to eliminating arguments between religions, each of which claimed to have \"the one and only revelation.',\n",
       " 'In his monograph on Frank Herbert, O\\'Reilly wrote that \"Dune is clearly a commentary on the Foundation trilogy.',\n",
       " \"[89]\\n\\nCalifornia State University, Fullerton's Pollack Library has several of Herbert's draft manuscripts of Dune and other works, with the author's notes, in their Frank Herbert Archives.\",\n",
       " \"Brian Herbert's and Anderson's Dune prequels first started publication in 1999, and have led to additional stories that take place between those of Frank Herbert's books.\",\n",
       " \"[92] The notes for what would have been Dune 7 also enabled them to publish Hunters of Dune (2006) and Sandworms of Dune (2007), sequels to Frank Herbert's final novel Chapterhouse: Dune, which complete the chronological progression of his original series, and wrap up storylines that began in Heretics of Dune.\",\n",
       " 'Frank Herbert traveled to Europe in 1976 to find that $2 million of the $9.',\n",
       " \"As he recalls, the pre-production process was slow, and finishing the project would have been even more time-intensive:\\n\\nBut after seven months I dropped out of Dune, by then Rudy Wurlitzer had come up with a first-draft script which I felt was a decent distillation of Frank Herbert's.\",\n",
       " \"[105]\\n\\nIn 2000, John Harrison adapted the novel into Frank Herbert's Dune, a miniseries which premiered on American Sci-Fi Channel.\",\n",
       " \"Anderson and Frank Herbert's son Brian Herbert, who had together written multiple Dune sequels and prequels since 1999, were attached to the project as technical advisors.\"]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Frank Herbert'\n",
    "regex = '[^.]*' + name + '[^.]*'\n",
    "matches = re.findall(regex, complete_text)\n",
    "[m.strip() + '.' for m in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229c539",
   "metadata": {
    "id": "8zM2VdMxWapN",
    "papermill": {
     "duration": 0.040095,
     "end_time": "2023-02-23T00:58:29.501851",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.461756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combine data from multiple files\n",
    "\n",
    "In some cases data sets contain many different information, as a result the content is split into different files:\n",
    "- We can open the required files through Python\n",
    "- We can load the required information using dictionaries for fast search over the data set\n",
    "- We can merge the data sets into strings to obtan the final data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12ec58",
   "metadata": {
    "id": "3Hbz_3amWapN",
    "papermill": {
     "duration": 0.040594,
     "end_time": "2023-02-23T00:58:29.582957",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.542363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading files\n",
    "\n",
    "We are going to work with the [Cornell Movie--Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html).\n",
    "You can download a copy of the original version of the corpus from this [link](http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip).\n",
    "\n",
    "Extract the content of the zip archive and put it into a `docs/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52c563",
   "metadata": {
    "id": "4SHdFvy_WapN",
    "papermill": {
     "duration": 0.039988,
     "end_time": "2023-02-23T00:58:29.663527",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.623539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are two main files in the corpus:\n",
    "- `movie_lines.txt` is a text file where each row is an utterance in a dialogue, it contains all the lines avaialble in the corpus\n",
    "- `movie_conversations.txt` is a text file where each row contains the list with the identifiers of the lines composing a dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebfdf9c",
   "metadata": {
    "id": "mVo6PAnMWapN",
    "papermill": {
     "duration": 0.040582,
     "end_time": "2023-02-23T00:58:29.744838",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.704256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First we load the utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f11c1bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:29.829430Z",
     "iopub.status.busy": "2023-02-23T00:58:29.828983Z",
     "iopub.status.idle": "2023-02-23T00:58:30.207644Z",
     "shell.execute_reply": "2023-02-23T00:58:30.206533Z"
    },
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1677006716234,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "xXDUxIoeWapO",
    "papermill": {
     "duration": 0.424785,
     "end_time": "2023-02-23T00:58:30.210384",
     "exception": false,
     "start_time": "2023-02-23T00:58:29.785599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/nlp-practical1/docs/cornell movie-dialogs corpus/movie_lines.txt') as f:\n",
    "    lines = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2424e11",
   "metadata": {
    "id": "rPe2bTm6WapO",
    "papermill": {
     "duration": 0.04034,
     "end_time": "2023-02-23T00:58:30.292233",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.251893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see what data we have in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e21692a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:30.376470Z",
     "iopub.status.busy": "2023-02-23T00:58:30.376019Z",
     "iopub.status.idle": "2023-02-23T00:58:30.382277Z",
     "shell.execute_reply": "2023-02-23T00:58:30.381037Z"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1677006720643,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "4Dr0KrGNWapO",
    "outputId": "d9d643c6-f4b5-4f7c-c50e-ce2dca348a58",
    "papermill": {
     "duration": 0.051612,
     "end_time": "2023-02-23T00:58:30.384822",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.333210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
      "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n",
      "L868 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ The \"real you\".\n",
      "L867 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ What good stuff?\n",
      "L866 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ I figured you'd get to the good stuff eventually.\n",
      "L865 +++$+++ u\n"
     ]
    }
   ],
   "source": [
    "print(lines[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25420dc4",
   "metadata": {
    "id": "aZgWvwiaWapO",
    "papermill": {
     "duration": 0.041753,
     "end_time": "2023-02-23T00:58:30.468631",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.426878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are three elements we want to keep:\n",
    "- line identifier\n",
    "- speaker\n",
    "- utterance text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4873be",
   "metadata": {
    "id": "cCI__BaXWapO",
    "papermill": {
     "duration": 0.040999,
     "end_time": "2023-02-23T00:58:30.551850",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.510851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then we load the dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf048d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:30.637404Z",
     "iopub.status.busy": "2023-02-23T00:58:30.636401Z",
     "iopub.status.idle": "2023-02-23T00:58:30.688986Z",
     "shell.execute_reply": "2023-02-23T00:58:30.688031Z"
    },
    "executionInfo": {
     "elapsed": 2578,
     "status": "ok",
     "timestamp": 1677006724391,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "20-CDIeCWapP",
    "papermill": {
     "duration": 0.097907,
     "end_time": "2023-02-23T00:58:30.691535",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.593628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/nlp-practical1/docs/cornell movie-dialogs corpus/movie_conversations.txt') as f:\n",
    "    lines_list = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f758e",
   "metadata": {
    "id": "8CDFb7OgWapP",
    "papermill": {
     "duration": 0.042554,
     "end_time": "2023-02-23T00:58:30.775877",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.733323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see what data we have in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4995af35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:30.860757Z",
     "iopub.status.busy": "2023-02-23T00:58:30.859513Z",
     "iopub.status.idle": "2023-02-23T00:58:30.866147Z",
     "shell.execute_reply": "2023-02-23T00:58:30.864906Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006726316,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "k10-S-NDWapP",
    "outputId": "ae0719bd-a377-4ce5-d6b1-26b39565580e",
    "papermill": {
     "duration": 0.051119,
     "end_time": "2023-02-23T00:58:30.868505",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.817386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L367', 'L368']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L401', 'L402', 'L403']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L404', 'L405', 'L406', 'L407']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L575', 'L576']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L577', 'L578']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L662', 'L663']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L693', 'L694', 'L695']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L696', 'L697', 'L69\n"
     ]
    }
   ],
   "source": [
    "print(lines_list[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994df4b",
   "metadata": {
    "id": "CfxzXx-0WapP",
    "papermill": {
     "duration": 0.041633,
     "end_time": "2023-02-23T00:58:30.953313",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.911680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we are interested in keeping only the list of identifiers composing a dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed90a6",
   "metadata": {
    "id": "9ryyyaJkWapP",
    "papermill": {
     "duration": 0.04139,
     "end_time": "2023-02-23T00:58:31.036255",
     "exception": false,
     "start_time": "2023-02-23T00:58:30.994865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Parsing content with RegEx\n",
    "\n",
    "Now we can use RegEx to extract the useful information we want.\n",
    "\n",
    "With RegEx we can define the structure of an entire string or piece of string and we can group pieces of our expressions.\n",
    "In this way we can retreive specific pieces of a string that matches our request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92695810",
   "metadata": {
    "id": "naZHebQGWapQ",
    "papermill": {
     "duration": 0.042316,
     "end_time": "2023-02-23T00:58:31.120723",
     "exception": false,
     "start_time": "2023-02-23T00:58:31.078407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each row in the lines file follows the same pattern:\n",
    "1. Line identifier\n",
    "2. Speaker identifier\n",
    "3. Movie identifier\n",
    "4. Speaker\n",
    "5. Utterance text\n",
    "\n",
    "We are interested in 1, 2, and 5.\n",
    "\n",
    "Note that we have a peculiar separator between the elements `+++$+++`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf68757",
   "metadata": {
    "id": "tfSaMUJ-WapQ",
    "papermill": {
     "duration": 0.043739,
     "end_time": "2023-02-23T00:58:31.207055",
     "exception": false,
     "start_time": "2023-02-23T00:58:31.163316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's write a RegEx first and apply it to the first rows.\n",
    "\n",
    "We use round brakets `()` to isolate groups (groups can be nested)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80c6000a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:31.351724Z",
     "iopub.status.busy": "2023-02-23T00:58:31.350435Z",
     "iopub.status.idle": "2023-02-23T00:58:31.361983Z",
     "shell.execute_reply": "2023-02-23T00:58:31.360206Z"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1677006731103,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "e4v_ZK56WapQ",
    "outputId": "dac86a6d-16a4-4471-8aea-55268ca54e00",
    "papermill": {
     "duration": 0.114624,
     "end_time": "2023-02-23T00:58:31.364538",
     "exception": false,
     "start_time": "2023-02-23T00:58:31.249914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression: '(L\\d+) \\+\\+\\+\\$\\+\\+\\+ u\\d+ \\+\\+\\+\\$\\+\\+\\+ m\\d+ \\+\\+\\+\\$\\+\\+\\+ ([\\w\\s]+) \\+\\+\\+\\$\\+\\+\\+ (.+)'\n",
      "Returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('L1045', 'BIANCA', 'They do not!'),\n",
       " ('L1044', 'CAMERON', 'They do to!'),\n",
       " ('L985', 'BIANCA', 'I hope so.'),\n",
       " ('L984', 'CAMERON', 'She okay?'),\n",
       " ('L925', 'BIANCA', \"Let's go.\"),\n",
       " ('L924', 'CAMERON', 'Wow'),\n",
       " ('L872', 'BIANCA', \"Okay -- you're gonna need to learn how to lie.\"),\n",
       " ('L871', 'CAMERON', 'No'),\n",
       " ('L870',\n",
       "  'BIANCA',\n",
       "  'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'),\n",
       " ('L869', 'BIANCA', 'Like my fear of wearing pastels?'),\n",
       " ('L868', 'CAMERON', 'The \"real you\".'),\n",
       " ('L867', 'BIANCA', 'What good stuff?'),\n",
       " ('L866', 'CAMERON', \"I figured you'd get to the good stuff eventually.\")]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = '(L\\d+) \\+\\+\\+\\$\\+\\+\\+ u\\d+ \\+\\+\\+\\$\\+\\+\\+ m\\d+ \\+\\+\\+\\$\\+\\+\\+ ([\\w\\s]+) \\+\\+\\+\\$\\+\\+\\+ (.+)'\n",
    "print(f\"Regular expression: '{regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(regex, lines[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa28ce",
   "metadata": {
    "id": "jkUpqREqWapQ",
    "papermill": {
     "duration": 0.041339,
     "end_time": "2023-02-23T00:58:31.448151",
     "exception": false,
     "start_time": "2023-02-23T00:58:31.406812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What do you see in output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c74fa",
   "metadata": {
    "id": "1wKLdQn8WapR",
    "papermill": {
     "duration": 0.04153,
     "end_time": "2023-02-23T00:58:31.531203",
     "exception": false,
     "start_time": "2023-02-23T00:58:31.489673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can retrieve the desired information from each line and use it to build a list dictionaries where the keys are the IDs of the lines.\n",
    "\n",
    "Each element of the dictionary will contain the speaker and the uttered text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce405e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:31.616054Z",
     "iopub.status.busy": "2023-02-23T00:58:31.614922Z",
     "iopub.status.idle": "2023-02-23T00:58:32.256795Z",
     "shell.execute_reply": "2023-02-23T00:58:32.255583Z"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1677006735061,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "1tHqch9nWapR",
    "papermill": {
     "duration": 0.687479,
     "end_time": "2023-02-23T00:58:32.259905",
     "exception": false,
     "start_time": "2023-02-23T00:58:31.572426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = {key: {'speaker': sp, 'text': txt} for key, sp, txt in re.findall(regex, lines)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3fddd5",
   "metadata": {
    "id": "lUpPJndGWapR",
    "papermill": {
     "duration": 0.041699,
     "end_time": "2023-02-23T00:58:32.344830",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.303131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can access the elements by specific names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab7189a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:32.432711Z",
     "iopub.status.busy": "2023-02-23T00:58:32.432046Z",
     "iopub.status.idle": "2023-02-23T00:58:32.439049Z",
     "shell.execute_reply": "2023-02-23T00:58:32.437759Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006735061,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "3g-jEg5YWapR",
    "outputId": "c87220ec-83f4-4560-9e08-cf2facaaa2a4",
    "papermill": {
     "duration": 0.052824,
     "end_time": "2023-02-23T00:58:32.441712",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.388888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'speaker': 'CAMERON', 'text': 'The \"real you\".'}\n",
      "<class 'dict'>\n",
      "BIANCA\n",
      "What good stuff?\n"
     ]
    }
   ],
   "source": [
    "print(type(lines))\n",
    "print(lines['L868'])\n",
    "print(type(lines['L868']))\n",
    "print(lines['L867']['speaker'])\n",
    "print(lines['L867']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882f8d0",
   "metadata": {
    "id": "bB_OozjfWapR",
    "papermill": {
     "duration": 0.040923,
     "end_time": "2023-02-23T00:58:32.524262",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.483339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can move to the dialogues file\n",
    "\n",
    "Each row in the dialogues file follows the same pattern:\n",
    "1. First speaker identifier\n",
    "2. Second speaker identifier\n",
    "3. Movie identifier\n",
    "4. List of lines identifier (expressed as a list of strings)\n",
    "\n",
    "We are interested only in 4.\n",
    "\n",
    "Note that we have again the peculiar separator between the elements `+++$+++`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aea4b5",
   "metadata": {
    "id": "U5ygdmjoWapS",
    "papermill": {
     "duration": 0.041141,
     "end_time": "2023-02-23T00:58:32.607122",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.565981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We split the search into two parts, first isolate the lists and then retrieve elements from the lists. Let's write a RegEx first and apply it to the first rows.\n",
    "\n",
    "**NOTE: this is not the smartest way to appraoch it, but it is useful to understand how regex work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "283fa43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:32.693064Z",
     "iopub.status.busy": "2023-02-23T00:58:32.692622Z",
     "iopub.status.idle": "2023-02-23T00:58:32.700425Z",
     "shell.execute_reply": "2023-02-23T00:58:32.699668Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006736185,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "2NwvbOV5WapS",
    "outputId": "5b88cc26-df22-4326-8cf1-a8fd7aa1a20c",
    "papermill": {
     "duration": 0.055365,
     "end_time": "2023-02-23T00:58:32.704083",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.648718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression: 'u\\d+ \\+\\+\\+\\$\\+\\+\\+ u\\d+ \\+\\+\\+\\$\\+\\+\\+ m\\d+ \\+\\+\\+\\$\\+\\+\\+ \\[(.+)\\]'\n",
      "Returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'L194', 'L195', 'L196', 'L197'\",\n",
       " \"'L198', 'L199'\",\n",
       " \"'L200', 'L201', 'L202', 'L203'\",\n",
       " \"'L204', 'L205', 'L206'\",\n",
       " \"'L207', 'L208'\",\n",
       " \"'L271', 'L272', 'L273', 'L274', 'L275'\",\n",
       " \"'L276', 'L277'\",\n",
       " \"'L280', 'L281'\",\n",
       " \"'L363', 'L364'\",\n",
       " \"'L365', 'L366'\",\n",
       " \"'L367', 'L368'\",\n",
       " \"'L401', 'L402', 'L403'\",\n",
       " \"'L404', 'L405', 'L406', 'L407'\",\n",
       " \"'L575', 'L576'\",\n",
       " \"'L577', 'L578'\",\n",
       " \"'L662', 'L663'\",\n",
       " \"'L693', 'L694', 'L695'\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_regex = 'u\\d+ \\+\\+\\+\\$\\+\\+\\+ u\\d+ \\+\\+\\+\\$\\+\\+\\+ m\\d+ \\+\\+\\+\\$\\+\\+\\+ \\[(.+)\\]'\n",
    "print(f\"Regular expression: '{list_regex}'\")\n",
    "print(\"Returns:\")\n",
    "re.findall(list_regex, lines_list[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a7d65a",
   "metadata": {
    "id": "t1ITZzv-WapS",
    "papermill": {
     "duration": 0.042427,
     "end_time": "2023-02-23T00:58:32.789286",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.746859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each element here is a string with the code of the line. We can search in each string separately the line IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07f34937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:32.877090Z",
     "iopub.status.busy": "2023-02-23T00:58:32.876319Z",
     "iopub.status.idle": "2023-02-23T00:58:32.885178Z",
     "shell.execute_reply": "2023-02-23T00:58:32.884098Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677006739427,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "7tqCn-3hWapS",
    "outputId": "162eebb5-a84e-4cf7-ba0e-36d1fe9c2580",
    "papermill": {
     "duration": 0.055532,
     "end_time": "2023-02-23T00:58:32.887368",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.831836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression: 'L\\d+'\n",
      "String: \"'L194', 'L195', 'L196', 'L197'\"\n",
      "Returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['L194', 'L195', 'L196', 'L197']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem_regex = 'L\\d+'\n",
    "s = re.findall(list_regex, lines_list[:1000])[0]\n",
    "print(f\"Regular expression: '{elem_regex}'\")\n",
    "print(f\"String: \\\"{s}\\\"\")\n",
    "print(\"Returns:\")\n",
    "re.findall(elem_regex, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e0340",
   "metadata": {
    "id": "5jGDOQEPWapS",
    "papermill": {
     "duration": 0.041483,
     "end_time": "2023-02-23T00:58:32.971576",
     "exception": false,
     "start_time": "2023-02-23T00:58:32.930093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are dealing with an actual list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f27323d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:33.057172Z",
     "iopub.status.busy": "2023-02-23T00:58:33.056467Z",
     "iopub.status.idle": "2023-02-23T00:58:33.062978Z",
     "shell.execute_reply": "2023-02-23T00:58:33.061539Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006740476,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "v5yVCWVjWapT",
    "outputId": "1f78ef47-16ec-47b7-d1e0-df208c44c7b0",
    "papermill": {
     "duration": 0.052376,
     "end_time": "2023-02-23T00:58:33.065673",
     "exception": false,
     "start_time": "2023-02-23T00:58:33.013297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(re.findall(elem_regex, s)))\n",
    "print(type(re.findall(elem_regex, s)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482a746",
   "metadata": {
    "id": "eN3HPpl4WapT",
    "papermill": {
     "duration": 0.043832,
     "end_time": "2023-02-23T00:58:33.152033",
     "exception": false,
     "start_time": "2023-02-23T00:58:33.108201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can retrieve the desired information from each line and use it to build a list, each element of the list is a list itself.\n",
    "The inner list contains the IDs of the lines composing the dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b215649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:33.239640Z",
     "iopub.status.busy": "2023-02-23T00:58:33.238922Z",
     "iopub.status.idle": "2023-02-23T00:58:33.623897Z",
     "shell.execute_reply": "2023-02-23T00:58:33.622736Z"
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1677006749430,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "1PV1s7CrWapT",
    "outputId": "e16b51fd-41e0-444a-a463-063834a9fbd5",
    "papermill": {
     "duration": 0.431219,
     "end_time": "2023-02-23T00:58:33.626534",
     "exception": false,
     "start_time": "2023-02-23T00:58:33.195315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208'],\n",
       " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
       " ['L276', 'L277'],\n",
       " ['L280', 'L281'],\n",
       " ['L363', 'L364'],\n",
       " ['L365', 'L366']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_list = [re.findall(elem_regex, s) for s in re.findall(list_regex, lines_list)]\n",
    "lines_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8114efb",
   "metadata": {
    "id": "0v99m8vsWapT",
    "papermill": {
     "duration": 0.042492,
     "end_time": "2023-02-23T00:58:33.711761",
     "exception": false,
     "start_time": "2023-02-23T00:58:33.669269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Composing the dialogues\n",
    "\n",
    "Now we have an indexed list of lines and a list of IDs composing a dialogue, we can finally put all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a95713",
   "metadata": {
    "id": "jRdZRwK1WapU",
    "papermill": {
     "duration": 0.041716,
     "end_time": "2023-02-23T00:58:33.796974",
     "exception": false,
     "start_time": "2023-02-23T00:58:33.755258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For each dialogue in `lines_list` we compose a string with all the turns separated by a newline character.\n",
    "A turn is a speaker-text pair in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff8c4e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:33.883947Z",
     "iopub.status.busy": "2023-02-23T00:58:33.883346Z",
     "iopub.status.idle": "2023-02-23T00:58:34.304164Z",
     "shell.execute_reply": "2023-02-23T00:58:34.302961Z"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1677006753188,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "Oyw0V3u9WapU",
    "outputId": "d1b22380-4f34-449b-ca3d-945efb7e2dc5",
    "papermill": {
     "duration": 0.467397,
     "end_time": "2023-02-23T00:58:34.306965",
     "exception": false,
     "start_time": "2023-02-23T00:58:33.839568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78120"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = [\n",
    "    '\\n'.join(f'{lines[idx][\"speaker\"]}: {lines[idx][\"text\"]}' for idx in indices) \n",
    "    for indices in lines_list if all(idx in lines for idx in indices)  # There are some missing \n",
    "]\n",
    "len(dialogues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195def65",
   "metadata": {
    "id": "adW8wds-WapU",
    "papermill": {
     "duration": 0.041776,
     "end_time": "2023-02-23T00:58:34.391926",
     "exception": false,
     "start_time": "2023-02-23T00:58:34.350150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can give a look to one of the extracted dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7af5a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:34.479234Z",
     "iopub.status.busy": "2023-02-23T00:58:34.478134Z",
     "iopub.status.idle": "2023-02-23T00:58:34.484252Z",
     "shell.execute_reply": "2023-02-23T00:58:34.482713Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006757457,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "EFiyNdDjWapU",
    "outputId": "ac2c56ff-88a4-41b3-99c1-a10625d70a43",
    "papermill": {
     "duration": 0.052336,
     "end_time": "2023-02-23T00:58:34.486849",
     "exception": false,
     "start_time": "2023-02-23T00:58:34.434513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIANCA: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "CAMERON: Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "BIANCA: Not the hacking and gagging and spitting part.  Please.\n",
      "CAMERON: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n"
     ]
    }
   ],
   "source": [
    "print(dialogues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e20868b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:34.574387Z",
     "iopub.status.busy": "2023-02-23T00:58:34.573946Z",
     "iopub.status.idle": "2023-02-23T00:58:34.579802Z",
     "shell.execute_reply": "2023-02-23T00:58:34.578660Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006758314,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "aH9T6tWNWapU",
    "outputId": "b0e88a7c-7c0a-4e8a-9a5a-19f763606584",
    "papermill": {
     "duration": 0.052903,
     "end_time": "2023-02-23T00:58:34.582988",
     "exception": false,
     "start_time": "2023-02-23T00:58:34.530085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRANK: You know him?\n",
      "JESSE: Heard of him.\n"
     ]
    }
   ],
   "source": [
    "print(dialogues[2307])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b581be",
   "metadata": {
    "id": "kzOu1jlTbKrC",
    "papermill": {
     "duration": 0.042212,
     "end_time": "2023-02-23T00:58:34.667718",
     "exception": false,
     "start_time": "2023-02-23T00:58:34.625506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading text from a PDF\n",
    "\n",
    "Much of the text on the internet is present inside PDF documents, and often we'd like to extract text from them. \n",
    "\n",
    "There are many different ways to do that in Python. Today we'll use the pdfplumber API: https://github.com/jsvine/pdfplumber\n",
    "- In order to use pdfplumber module, we first need to install it. \n",
    "- We can do that from inside the jupyter notebook by calling the pip3 command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5d2ac6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:34.754782Z",
     "iopub.status.busy": "2023-02-23T00:58:34.754227Z",
     "iopub.status.idle": "2023-02-23T00:58:50.831352Z",
     "shell.execute_reply": "2023-02-23T00:58:50.829513Z"
    },
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1677006844287,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "UQ_Q1rEPbKrC",
    "outputId": "567cd6b1-2950-4ebe-e12e-b76a9682660e",
    "papermill": {
     "duration": 16.124912,
     "end_time": "2023-02-23T00:58:50.835185",
     "exception": false,
     "start_time": "2023-02-23T00:58:34.710273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.8.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m195.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Wand>=0.6.10 in /opt/conda/lib/python3.7/site-packages (from pdfplumber) (0.6.11)\r\n",
      "Collecting pdfminer.six==20221105\r\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.7/site-packages (from pdfplumber) (9.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from pdfminer.six==20221105->pdfplumber) (4.1.1)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.7/site-packages (from pdfminer.six==20221105->pdfplumber) (37.0.4)\r\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from pdfminer.six==20221105->pdfplumber) (2.1.1)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\r\n",
      "Installing collected packages: pdfminer.six, pdfplumber\r\n",
      "Successfully installed pdfminer.six-20221105 pdfplumber-0.8.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad56be0d",
   "metadata": {
    "id": "Sic3jHSObKrC",
    "papermill": {
     "duration": 0.046768,
     "end_time": "2023-02-23T00:58:50.931449",
     "exception": false,
     "start_time": "2023-02-23T00:58:50.884681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can import the module and use it to extract content from a PDF. \n",
    "- Let's try extracting content from this NLP reasearch paper: https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf\n",
    "- The HTTPS server won't allow us direct programmatic access, so you'll need to use the file in the `docs/` directory on WeBeep where you found this notebook (as we did with the original Alice text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0dea479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:51.026378Z",
     "iopub.status.busy": "2023-02-23T00:58:51.025921Z",
     "iopub.status.idle": "2023-02-23T00:58:51.091328Z",
     "shell.execute_reply": "2023-02-23T00:58:51.090239Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677006849925,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "NN-4B_UIbKrD",
    "papermill": {
     "duration": 0.116075,
     "end_time": "2023-02-23T00:58:51.093965",
     "exception": false,
     "start_time": "2023-02-23T00:58:50.977890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "filename = '/kaggle/input/nlp-practical1/docs/collobert11a.pdf'\n",
    "pdf = pdfplumber.open(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9f6fc",
   "metadata": {
    "id": "C49W1ARdbKrD",
    "papermill": {
     "duration": 0.046068,
     "end_time": "2023-02-23T00:58:51.185041",
     "exception": false,
     "start_time": "2023-02-23T00:58:51.138973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How many pages are in the report? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cebf109f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:51.279111Z",
     "iopub.status.busy": "2023-02-23T00:58:51.278687Z",
     "iopub.status.idle": "2023-02-23T00:58:51.323455Z",
     "shell.execute_reply": "2023-02-23T00:58:51.322301Z"
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1677006854377,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "MzALGQywbKrD",
    "outputId": "33fe11de-29a9-420c-ffd0-2b28a582e9e5",
    "papermill": {
     "duration": 0.094195,
     "end_time": "2023-02-23T00:58:51.325891",
     "exception": false,
     "start_time": "2023-02-23T00:58:51.231696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf.pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc9521",
   "metadata": {
    "id": "NZXe04dobKrD",
    "papermill": {
     "duration": 0.048065,
     "end_time": "2023-02-23T00:58:51.419832",
     "exception": false,
     "start_time": "2023-02-23T00:58:51.371767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wow, that's not a lot of pages!\n",
    "\n",
    "We can have a look at the first couple of pages extracting the text from them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46719875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:51.513390Z",
     "iopub.status.busy": "2023-02-23T00:58:51.512861Z",
     "iopub.status.idle": "2023-02-23T00:58:51.696815Z",
     "shell.execute_reply": "2023-02-23T00:58:51.695439Z"
    },
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1677006859781,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "nM4yYdfjbKrD",
    "outputId": "3ee6b819-87c0-4568-ffe7-6f3d55f420e8",
    "papermill": {
     "duration": 0.233963,
     "end_time": "2023-02-23T00:58:51.699821",
     "exception": false,
     "start_time": "2023-02-23T00:58:51.465858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journal of Machine Learning Research 12 (2011) 2493-2537 Submitted 1/10; Revised 11/10; Published 8/11\n",
      "Natural Language Processing (Almost) from Scratch\n",
      "Ronan Collobert∗ RONAN@COLLOBERT.COM\n",
      "Jason Weston† JWESTON@GOOGLE.COM\n",
      "Le´on Bottou‡ LEON@BOTTOU.ORG\n",
      "Michael Karlen MICHAEL.KARLEN@GMAIL.COM\n",
      "Koray Kavukcuoglu§ KORAY@CS.NYU.EDU\n",
      "Pavel Kuksa¶ PKUKSA@CS.RUTGERS.EDU\n",
      "NEC Laboratories America\n",
      "4 Independence Way\n",
      "Princeton, NJ 08540\n",
      "Editor: Michael Collins\n",
      "Abstract\n",
      "We propose a uniﬁed neural network architecture and learning algorithm that can be applied to var-\n",
      "ious natural language processing tasks including part-of-speech tagging, chunking, named entity\n",
      "recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-speciﬁc\n",
      "engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made\n",
      "input features carefully optimized for each task, our system learns internal representations on the\n",
      "basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for\n",
      "building a freely available tagging system with good performance and minimal computational re-\n",
      "quirements.\n",
      "Keywords: natural language processing, neural networks\n",
      "1. Introduction\n",
      "Will a computer program ever be able to convert a piece of English text into a programmer friendly\n",
      "data structure that describes the meaning of the natural language text? Unfortunately, no consensus\n",
      "has emerged about the form or the existence of such a data structure. Until such fundamental\n",
      "Articial Intelligence problems are resolved, computer scientists must settle for the reduced objective\n",
      "of extracting simpler representations that describe limited aspects of the textual information.\n",
      "These simpler representations are often motivated by speciﬁc applications (for instance, bag-\n",
      "of-words variants for information retrieval), or by our belief that they capture something more gen-\n",
      "eral about natural language. They can describe syntactic information (e.g., part-of-speech tagging,\n",
      "chunking, and parsing) or semantic information (e.g., word-sense disambiguation, semantic role\n",
      "labeling, named entity extraction, and anaphora resolution). Text corpora have been manually an-\n",
      "notated with such data structures in order to compare the performance of various systems. The\n",
      "availability of standard benchmarks has stimulated research in Natural Language Processing (NLP)\n",
      "∗. Ronan Collobert is now with the Idiap Research Institute, Switzerland.\n",
      "†. Jason Weston is now with Google, New York, NY.\n",
      "‡. Le´on Bottou is now with Microsoft, Redmond, WA.\n",
      "§. Koray Kavukcuoglu is also with New York University, New York, NY.\n",
      "¶. Pavel Kuksa is also with Rutgers University, New Brunswick, NJ.\n",
      "(cid:13)c2011 Ronan Collobert, Jason Weston, Le´on Bottou, Michael Karlen, Koray Kavukcuoglu and Pavel Kuksa.\n"
     ]
    }
   ],
   "source": [
    "text = pdf.pages[0].extract_text(x_tolerance=1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a093e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:51.792393Z",
     "iopub.status.busy": "2023-02-23T00:58:51.791985Z",
     "iopub.status.idle": "2023-02-23T00:58:52.010543Z",
     "shell.execute_reply": "2023-02-23T00:58:52.008565Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677006864590,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "lXRuv5mibKrD",
    "outputId": "969a7a4a-cd57-431b-8450-54b630b693de",
    "papermill": {
     "duration": 0.268804,
     "end_time": "2023-02-23T00:58:52.013962",
     "exception": false,
     "start_time": "2023-02-23T00:58:51.745158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLOBERT, WESTON, BOTTOU, KARLEN, KAVUKCUOGLU AND KUKSA\n",
      "and effective systems have been designed for all these tasks. Such systems are often viewed as\n",
      "software components for constructing real-world NLP solutions.\n",
      "The overwhelming majority of these state-of-the-art systems address their single benchmark\n",
      "task by applying linear statistical models to ad-hoc features. In other words, the researchers them-\n",
      "selves discover intermediate representations by engineering task-speciﬁc features. These features\n",
      "are often derived from the output of preexisting systems, leading to complex runtime dependencies.\n",
      "This approach is effective because researchers leverage a large body of linguistic knowledge. On\n",
      "the other hand, there is a great temptation to optimize the performance of a system for a speciﬁc\n",
      "benchmark. Although such performance improvements can be very useful in practice, they teach us\n",
      "little about the means to progress toward the broader goals of natural language understanding and\n",
      "the elusive goals of Artiﬁcial Intelligence.\n",
      "In this contribution, we try to excel on multiple benchmarks while avoiding task-speciﬁc engi-\n",
      "neering. Instead we use a single learning system able to discover adequate internal representations.\n",
      "In fact we view the benchmarks as indirect measurements of the relevance of the internal represen-\n",
      "tations discovered by the learning procedure, and we posit that these intermediate representations\n",
      "are more general than any of the benchmarks. Our desire to avoid task-speciﬁc engineered features\n",
      "prevented us from using a large body of linguistic knowledge. Instead we reach good performance\n",
      "levels in most of the tasks by transferring intermediate representations discovered on large unlabeled\n",
      "data sets. We call this approach “almost from scratch” to emphasize the reduced (but still important)\n",
      "reliance on a priori NLP knowledge.\n",
      "The paper is organized as follows. Section 2 describes the benchmark tasks of interest. Sec-\n",
      "tion 3 describes the uniﬁed model and reports benchmark results obtained with supervised training.\n",
      "Section 4 leverages large unlabeled data sets (∼ 852 million words) to train the model on a language\n",
      "modeling task. Performance improvements are then demonstrated by transferring the unsupervised\n",
      "internal representations into the supervised benchmark models. Section 5 investigates multitask\n",
      "supervised training. Section 6 then evaluates how much further improvement can be achieved by\n",
      "incorporating standard NLP task-speciﬁc engineering into our systems. Drifting away from our ini-\n",
      "tial goals gives us the opportunity to construct an all-purpose tagger that is simultaneously accurate,\n",
      "practical, and fast. We then conclude with a short discussion section.\n",
      "2. The Benchmark Tasks\n",
      "In this section, we brieﬂy introduce four standard NLP tasks on which we will benchmark our\n",
      "architectures within this paper: Part-Of-Speech tagging (POS), chunking (CHUNK), Named Entity\n",
      "Recognition (NER) and Semantic Role Labeling (SRL). For each of them, we consider a standard\n",
      "experimental setup and give an overview of state-of-the-art systems on this setup. The experimental\n",
      "setups are summarized in Table 1, while state-of-the-art systems are reported in Table 2.\n",
      "2.1 Part-Of-Speech Tagging\n",
      "POS aims at labeling each word with a unique tag that indicates its syntactic role, for example, plural\n",
      "noun, adverb, . . . A standard benchmark setup is described in detail by Toutanova et al. (2003).\n",
      "Sections 0–18 of Wall Street Journal (WSJ) data are used for training, while sections 19–21 are for\n",
      "validation and sections 22–24 for testing.\n",
      "The best POS classiﬁers are based on classiﬁers trained on windows of text, which are then fed\n",
      "to a bidirectional decoding algorithm during inference. Features include preceding and following\n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "text = pdf.pages[1].extract_text(x_tolerance=1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656fc90",
   "metadata": {
    "id": "5oNjvSm1bKrD",
    "papermill": {
     "duration": 0.045861,
     "end_time": "2023-02-23T00:58:52.105686",
     "exception": false,
     "start_time": "2023-02-23T00:58:52.059825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Extract the text from all the pages of the document into a list\n",
    "- Note: this might take a minute. There are a lot of pages ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6513bf06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:58:52.198716Z",
     "iopub.status.busy": "2023-02-23T00:58:52.198123Z",
     "iopub.status.idle": "2023-02-23T00:59:00.755774Z",
     "shell.execute_reply": "2023-02-23T00:59:00.754496Z"
    },
    "executionInfo": {
     "elapsed": 8181,
     "status": "ok",
     "timestamp": 1677006880830,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "xCuTTuvSbKrD",
    "papermill": {
     "duration": 8.607699,
     "end_time": "2023-02-23T00:59:00.758852",
     "exception": false,
     "start_time": "2023-02-23T00:58:52.151153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [page.extract_text(x_tolerance=1) for page in pdf.pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883632c",
   "metadata": {
    "id": "fFdEPAa0bKrD",
    "papermill": {
     "duration": 0.045153,
     "end_time": "2023-02-23T00:59:00.849457",
     "exception": false,
     "start_time": "2023-02-23T00:59:00.804304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now concatenate all the text together into a single string. \n",
    "- We'll separate them from one another using a couple of newline characters and some spaces too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4122f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:00.943567Z",
     "iopub.status.busy": "2023-02-23T00:59:00.942718Z",
     "iopub.status.idle": "2023-02-23T00:59:00.947956Z",
     "shell.execute_reply": "2023-02-23T00:59:00.946699Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1677006880831,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "VA2Je3JpbKrE",
    "outputId": "5f8cb7e6-61cd-48a2-e109-40c1d828e885",
    "papermill": {
     "duration": 0.055096,
     "end_time": "2023-02-23T00:59:00.950332",
     "exception": false,
     "start_time": "2023-02-23T00:59:00.895236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"  \\n\\n\".join(texts)\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03eb277",
   "metadata": {
    "id": "R8XeouXkbKrE",
    "papermill": {
     "duration": 0.04486,
     "end_time": "2023-02-23T00:59:01.040280",
     "exception": false,
     "start_time": "2023-02-23T00:59:00.995420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Using Regular Expressions to search PDF \n",
    "\n",
    "Use some regular expressions to search through the text for some interesting content. \n",
    "- You could look for email addresses, phone numbers, addresses, ...\n",
    "- Let's try first to look for email addresses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17081904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:01.132796Z",
     "iopub.status.busy": "2023-02-23T00:59:01.132408Z",
     "iopub.status.idle": "2023-02-23T00:59:01.146685Z",
     "shell.execute_reply": "2023-02-23T00:59:01.145558Z"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1677006935956,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "nXMhf0aNbKrE",
    "outputId": "e9c96737-0d56-456f-8bc6-5dd9239b6043",
    "papermill": {
     "duration": 0.064423,
     "end_time": "2023-02-23T00:59:01.150103",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.085680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RONAN@COLLOBERT.COM', 'JWESTON@GOOGLE.COM', 'LEON@BOTTOU.ORG', 'MICHAEL.KARLEN@GMAIL.COM', 'KORAY@CS.NYU.EDU', 'PKUKSA@CS.RUTGERS.EDU']\n"
     ]
    }
   ],
   "source": [
    "regex = '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "emails = re.findall(regex,text)\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e2a8f",
   "metadata": {
    "id": "zqzxkQ28bKrE",
    "papermill": {
     "duration": 0.04516,
     "end_time": "2023-02-23T00:59:01.243866",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.198706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Did you find any? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a70f8",
   "metadata": {
    "id": "y5XPlU-1WapY",
    "papermill": {
     "duration": 0.045348,
     "end_time": "2023-02-23T00:59:01.334912",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.289564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "POS, Chunking, NER, and SRL are all NLP tasks. \n",
    "- Are they mentioned anywhere in the paper? \n",
    "- Write a regular expression to find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "678da27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:01.428752Z",
     "iopub.status.busy": "2023-02-23T00:59:01.428359Z",
     "iopub.status.idle": "2023-02-23T00:59:01.433202Z",
     "shell.execute_reply": "2023-02-23T00:59:01.431741Z"
    },
    "id": "JabBh00YbKrE",
    "papermill": {
     "duration": 0.054437,
     "end_time": "2023-02-23T00:59:01.435722",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.381285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fee963",
   "metadata": {
    "id": "F-eWNcQbbKrE",
    "papermill": {
     "duration": 0.045379,
     "end_time": "2023-02-23T00:59:01.526612",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.481233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Other ideas to try:\n",
    "- In this period reaserchers started using neural networks to solve NLP. Find out where neural networks are mentioned in the report and in what context.\n",
    "- Theauthors use a data set composed of text coming from the Wall Street Journal (WSJ). Search for references to it in the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0feaa3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:01.621356Z",
     "iopub.status.busy": "2023-02-23T00:59:01.620617Z",
     "iopub.status.idle": "2023-02-23T00:59:01.624748Z",
     "shell.execute_reply": "2023-02-23T00:59:01.623885Z"
    },
    "id": "UPGXsTFFbKrE",
    "papermill": {
     "duration": 0.053405,
     "end_time": "2023-02-23T00:59:01.626848",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.573443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b8085",
   "metadata": {
    "id": "XBR_N4eQbKrE",
    "papermill": {
     "duration": 0.045303,
     "end_time": "2023-02-23T00:59:01.719620",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.674317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load another PDF and write regular expressions to search for content in it. \n",
    "- For example, you can find reports for Ferrari here: https://corporate.ferrari.com/en/investors/results/reports\n",
    "- Let's load an interim report from September 2020 (you can find it in the same `docs` folder as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c901b343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:01.815756Z",
     "iopub.status.busy": "2023-02-23T00:59:01.815014Z",
     "iopub.status.idle": "2023-02-23T00:59:15.554959Z",
     "shell.execute_reply": "2023-02-23T00:59:15.553731Z"
    },
    "executionInfo": {
     "elapsed": 13504,
     "status": "ok",
     "timestamp": 1677006961536,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "zzSw45EtbKrF",
    "outputId": "0d5aacda-56a1-407d-8290-8397ce35bb3a",
    "papermill": {
     "duration": 13.790081,
     "end_time": "2023-02-23T00:59:15.557858",
     "exception": false,
     "start_time": "2023-02-23T00:59:01.767777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '/kaggle/input/nlp-practical1/docs/ferrari_interim_report_at_and_for_the_three_and_nine_months_ended_september_30_2020.pdf'\n",
    "pdf = pdfplumber.open(filename)\n",
    "text = '\\n\\n'.join([page.extract_text() for page in pdf.pages])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ebbf1a",
   "metadata": {
    "id": "nd8hAX4aV0JK",
    "papermill": {
     "duration": 0.045358,
     "end_time": "2023-02-23T00:59:15.649302",
     "exception": false,
     "start_time": "2023-02-23T00:59:15.603944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extracting Tables from a PDF \n",
    "\n",
    "Sometimes it can be useful to extract tabular data from a PDF. \n",
    "- Tools exist that allow you to do this programmatically, making the extraction process semi-automatic.\n",
    "- One tool that can do this is the *tabula* library. Let's install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dff66803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:15.744872Z",
     "iopub.status.busy": "2023-02-23T00:59:15.744120Z",
     "iopub.status.idle": "2023-02-23T00:59:30.338255Z",
     "shell.execute_reply": "2023-02-23T00:59:30.336550Z"
    },
    "executionInfo": {
     "elapsed": 5602,
     "status": "ok",
     "timestamp": 1677006978213,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "3_rwPuYmGCVc",
    "outputId": "8b047957-0a6e-4662-8a99-237523fccb58",
    "papermill": {
     "duration": 14.646602,
     "end_time": "2023-02-23T00:59:30.341433",
     "exception": false,
     "start_time": "2023-02-23T00:59:15.694831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting tabula-py\r\n",
      "  Downloading tabula_py-2.6.0-py3-none-any.whl (12.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /opt/conda/lib/python3.7/site-packages (from tabula-py) (1.3.5)\r\n",
      "Collecting distro\r\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tabula-py) (1.21.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.3->tabula-py) (2022.2.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->tabula-py) (1.16.0)\r\n",
      "Installing collected packages: distro, tabula-py\r\n",
      "Successfully installed distro-1.8.0 tabula-py-2.6.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tabula-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f39c8",
   "metadata": {
    "id": "naFDi4yNWyY9",
    "papermill": {
     "duration": 0.048174,
     "end_time": "2023-02-23T00:59:30.438859",
     "exception": false,
     "start_time": "2023-02-23T00:59:30.390685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can use *tabula* to extract all the tables from Ferrari's interim report above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22f421b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:30.538178Z",
     "iopub.status.busy": "2023-02-23T00:59:30.537710Z",
     "iopub.status.idle": "2023-02-23T00:59:46.789899Z",
     "shell.execute_reply": "2023-02-23T00:59:46.788189Z"
    },
    "executionInfo": {
     "elapsed": 25205,
     "status": "ok",
     "timestamp": 1677007010328,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "-pQwzInjG8Rt",
    "papermill": {
     "duration": 16.305626,
     "end_time": "2023-02-23T00:59:46.792865",
     "exception": false,
     "start_time": "2023-02-23T00:59:30.487239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tabula \n",
    "tables = tabula.read_pdf(filename, pages=\"all\", multiple_tables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7087a0",
   "metadata": {
    "id": "RNrQUIGrX6Rn",
    "papermill": {
     "duration": 0.048323,
     "end_time": "2023-02-23T00:59:46.889726",
     "exception": false,
     "start_time": "2023-02-23T00:59:46.841403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's have a look at some of the tables produced\n",
    "- the first table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acd64639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:46.990126Z",
     "iopub.status.busy": "2023-02-23T00:59:46.989672Z",
     "iopub.status.idle": "2023-02-23T00:59:47.012399Z",
     "shell.execute_reply": "2023-02-23T00:59:47.010838Z"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1677007016242,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "86E4O5vDH8Hq",
    "outputId": "81a7b76c-643b-4be8-b9b1-e9fba57fbd08",
    "papermill": {
     "duration": 0.075615,
     "end_time": "2023-02-23T00:59:47.014949",
     "exception": false,
     "start_time": "2023-02-23T00:59:46.939334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2020</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2019 2020</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>2019</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(€ million, except per share data)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Net revenues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>888</td>\n",
       "      <td>915</td>\n",
       "      <td>2,391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222</td>\n",
       "      <td>227</td>\n",
       "      <td>465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Profit before taxes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208</td>\n",
       "      <td>211</td>\n",
       "      <td>427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Net profit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171</td>\n",
       "      <td>169</td>\n",
       "      <td>346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Net profit attributable to:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Owners of the parent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171</td>\n",
       "      <td>168</td>\n",
       "      <td>346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-controlling interests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—</td>\n",
       "      <td>1</td>\n",
       "      <td>—</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Basic earnings per common share (in Euro) (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diluted earnings per common share (in Euro) (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dividend declared per common share (in Euro) (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dividend declared per common share (in USD) (2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_____________________________</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Unnamed: 0  2020 Unnamed: 1  \\\n",
       "0                                                 NaN   NaN        NaN   \n",
       "1                                        Net revenues   NaN        888   \n",
       "2                                                EBIT   NaN        222   \n",
       "3                                 Profit before taxes   NaN        208   \n",
       "4                                          Net profit   NaN        171   \n",
       "5                         Net profit attributable to:   NaN        NaN   \n",
       "6                                Owners of the parent   NaN        171   \n",
       "7                           Non-controlling interests   NaN          —   \n",
       "8       Basic earnings per common share (in Euro) (1)   NaN       0.92   \n",
       "9     Diluted earnings per common share (in Euro) (1)   NaN       0.92   \n",
       "10  Dividend declared per common share (in Euro) (...   NaN       1.13   \n",
       "11  Dividend declared per common share (in USD) (2...   NaN       1.23   \n",
       "12                      _____________________________   NaN        NaN   \n",
       "\n",
       "                             2019 2020 Unnamed: 2  2019 Unnamed: 3  \n",
       "0   (€ million, except per share data)        NaN   NaN        NaN  \n",
       "1                                  915      2,391   NaN      2,839  \n",
       "2                                  227        465   NaN        698  \n",
       "3                                  211        427   NaN        666  \n",
       "4                                  169        346   NaN        533  \n",
       "5                                  NaN        NaN   NaN        NaN  \n",
       "6                                  168        346   NaN        529  \n",
       "7                                    1          —   NaN          4  \n",
       "8                                 0.90       1.87   NaN       2.82  \n",
       "9                                 0.90       1.86   NaN       2.81  \n",
       "10                                1.03       1.13   NaN       1.03  \n",
       "11                                1.16       1.23   NaN       1.16  \n",
       "12                                 NaN        NaN   NaN        NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e3532",
   "metadata": {
    "id": "WXPN-2SDYCao",
    "papermill": {
     "duration": 0.048028,
     "end_time": "2023-02-23T00:59:47.111860",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.063832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- the third table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cd917e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:47.215314Z",
     "iopub.status.busy": "2023-02-23T00:59:47.214872Z",
     "iopub.status.idle": "2023-02-23T00:59:47.234274Z",
     "shell.execute_reply": "2023-02-23T00:59:47.233083Z"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1677007029888,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "4fOAuloxYKvp",
    "outputId": "6866188f-a006-4b77-ad30-aa52b1d3c4af",
    "papermill": {
     "duration": 0.073708,
     "end_time": "2023-02-23T00:59:47.236558",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.162850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2020</th>\n",
       "      <th>%</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2019</th>\n",
       "      <th>%.1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>2020.1</th>\n",
       "      <th>%.2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>2019.1</th>\n",
       "      <th>%.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>269</td>\n",
       "      <td>11.6 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262</td>\n",
       "      <td>10.6 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>796</td>\n",
       "      <td>12.4 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709</td>\n",
       "      <td>9.1 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>247</td>\n",
       "      <td>10.7 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202</td>\n",
       "      <td>8.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>689</td>\n",
       "      <td>10.7 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>782</td>\n",
       "      <td>10.1 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>149</td>\n",
       "      <td>6.4 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>5.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437</td>\n",
       "      <td>6.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431</td>\n",
       "      <td>5.6 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>123</td>\n",
       "      <td>5.3 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>4.4 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327</td>\n",
       "      <td>5.1 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320</td>\n",
       "      <td>4.1 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>121</td>\n",
       "      <td>5.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>4.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303</td>\n",
       "      <td>4.7 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334</td>\n",
       "      <td>4.3 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Middle East (2)</td>\n",
       "      <td>64</td>\n",
       "      <td>2.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>3.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190</td>\n",
       "      <td>3.0 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193</td>\n",
       "      <td>2.5 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other EMEA (3)</td>\n",
       "      <td>315</td>\n",
       "      <td>13.7 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244</td>\n",
       "      <td>9.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>11.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778</td>\n",
       "      <td>10.0 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total EMEA</td>\n",
       "      <td>1,288</td>\n",
       "      <td>55.7 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,143</td>\n",
       "      <td>46.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,510</td>\n",
       "      <td>54.5 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,547</td>\n",
       "      <td>45.7 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Americas (4)</td>\n",
       "      <td>504</td>\n",
       "      <td>21.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>772</td>\n",
       "      <td>31.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,635</td>\n",
       "      <td>25.4 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,295</td>\n",
       "      <td>29.6 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mainland China, Hong Kong and Taiwan</td>\n",
       "      <td>119</td>\n",
       "      <td>5.1 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159</td>\n",
       "      <td>6.4 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181</td>\n",
       "      <td>2.8 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>776</td>\n",
       "      <td>10.0 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rest of APAC (5)</td>\n",
       "      <td>402</td>\n",
       "      <td>17.4 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>16.2 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,114</td>\n",
       "      <td>17.3 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,137</td>\n",
       "      <td>14.7 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total</td>\n",
       "      <td>2,313</td>\n",
       "      <td>100.0 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,474</td>\n",
       "      <td>100.0 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,440</td>\n",
       "      <td>100.0 %</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7,755</td>\n",
       "      <td>100.0 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>_____________________________</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Unnamed: 0   2020        %  Unnamed: 1   2019  \\\n",
       "0                                   EMEA    NaN      NaN         NaN    NaN   \n",
       "1                                Germany    269   11.6 %         NaN    262   \n",
       "2                                     UK    247   10.7 %         NaN    202   \n",
       "3                                  Italy    149    6.4 %         NaN    128   \n",
       "4                            Switzerland    123    5.3 %         NaN    109   \n",
       "5                                 France    121    5.2 %         NaN    118   \n",
       "6                        Middle East (2)     64    2.8 %         NaN     80   \n",
       "7                         Other EMEA (3)    315   13.7 %         NaN    244   \n",
       "8                             Total EMEA  1,288   55.7 %         NaN  1,143   \n",
       "9                           Americas (4)    504   21.8 %         NaN    772   \n",
       "10  Mainland China, Hong Kong and Taiwan    119    5.1 %         NaN    159   \n",
       "11                      Rest of APAC (5)    402   17.4 %         NaN    400   \n",
       "12                                 Total  2,313  100.0 %         NaN  2,474   \n",
       "13         _____________________________    NaN      NaN         NaN    NaN   \n",
       "\n",
       "        %.1  Unnamed: 2 2020.1      %.2  Unnamed: 3 2019.1      %.3  \n",
       "0       NaN         NaN    NaN      NaN         NaN    NaN      NaN  \n",
       "1    10.6 %         NaN    796   12.4 %         NaN    709    9.1 %  \n",
       "2     8.2 %         NaN    689   10.7 %         NaN    782   10.1 %  \n",
       "3     5.2 %         NaN    437    6.8 %         NaN    431    5.6 %  \n",
       "4     4.4 %         NaN    327    5.1 %         NaN    320    4.1 %  \n",
       "5     4.8 %         NaN    303    4.7 %         NaN    334    4.3 %  \n",
       "6     3.2 %         NaN    190    3.0 %         NaN    193    2.5 %  \n",
       "7     9.8 %         NaN    768   11.8 %         NaN    778   10.0 %  \n",
       "8    46.2 %         NaN  3,510   54.5 %         NaN  3,547   45.7 %  \n",
       "9    31.2 %         NaN  1,635   25.4 %         NaN  2,295   29.6 %  \n",
       "10    6.4 %         NaN    181    2.8 %         NaN    776   10.0 %  \n",
       "11   16.2 %         NaN  1,114   17.3 %         NaN  1,137   14.7 %  \n",
       "12  100.0 %         NaN  6,440  100.0 %         NaN  7,755  100.0 %  \n",
       "13      NaN         NaN    NaN      NaN         NaN    NaN      NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135426de",
   "metadata": {
    "id": "tDCG8UeAYbwM",
    "papermill": {
     "duration": 0.048713,
     "end_time": "2023-02-23T00:59:47.334585",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.285872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be seen that the tables are in need of a bit of cleaning to make them usable. \n",
    "- The tables are Pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "caba868e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:47.435020Z",
     "iopub.status.busy": "2023-02-23T00:59:47.434601Z",
     "iopub.status.idle": "2023-02-23T00:59:47.441353Z",
     "shell.execute_reply": "2023-02-23T00:59:47.440528Z"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1677007054244,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "GWqHAlmoJSaS",
    "outputId": "ae0e53c2-47ae-4253-cb35-0c351b28bfbe",
    "papermill": {
     "duration": 0.059519,
     "end_time": "2023-02-23T00:59:47.443478",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.383959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tables[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c31425",
   "metadata": {
    "id": "reWHSqBOYwcU",
    "papermill": {
     "duration": 0.048977,
     "end_time": "2023-02-23T00:59:47.541970",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.492993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So we can clean-up the table by:\n",
    "- dropping some columns\n",
    "- dropping some rows\n",
    "- renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "871793c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T00:59:47.643719Z",
     "iopub.status.busy": "2023-02-23T00:59:47.642925Z",
     "iopub.status.idle": "2023-02-23T00:59:47.665225Z",
     "shell.execute_reply": "2023-02-23T00:59:47.664065Z"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1677007059263,
     "user": {
      "displayName": "Vincenzo Scotti",
      "userId": "11083671475743415769"
     },
     "user_tz": -60
    },
    "id": "YlpIdJI0Jt-n",
    "outputId": "9060daa1-f1c4-44cc-911a-86e93261952f",
    "papermill": {
     "duration": 0.075457,
     "end_time": "2023-02-23T00:59:47.667727",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.592270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>3months_to_30092020</th>\n",
       "      <th>3months_to_30092019</th>\n",
       "      <th>9months_to_30092020</th>\n",
       "      <th>9months_to_30092019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Net revenues</td>\n",
       "      <td>888</td>\n",
       "      <td>915</td>\n",
       "      <td>2,391</td>\n",
       "      <td>2,839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>222</td>\n",
       "      <td>227</td>\n",
       "      <td>465</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Profit before taxes</td>\n",
       "      <td>208</td>\n",
       "      <td>211</td>\n",
       "      <td>427</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Net profit</td>\n",
       "      <td>171</td>\n",
       "      <td>169</td>\n",
       "      <td>346</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Owners of the parent</td>\n",
       "      <td>171</td>\n",
       "      <td>168</td>\n",
       "      <td>346</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-controlling interests</td>\n",
       "      <td>—</td>\n",
       "      <td>1</td>\n",
       "      <td>—</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Basic earnings per common share (in Euro) (1)</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diluted earnings per common share (in Euro) (1)</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dividend declared per common share (in Euro) (...</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dividend declared per common share (in USD) (2...</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Field 3months_to_30092020  \\\n",
       "0                                       Net revenues                 888   \n",
       "1                                               EBIT                 222   \n",
       "2                                Profit before taxes                 208   \n",
       "3                                         Net profit                 171   \n",
       "4                               Owners of the parent                 171   \n",
       "5                          Non-controlling interests                   —   \n",
       "6      Basic earnings per common share (in Euro) (1)                0.92   \n",
       "7    Diluted earnings per common share (in Euro) (1)                0.92   \n",
       "8  Dividend declared per common share (in Euro) (...                1.13   \n",
       "9  Dividend declared per common share (in USD) (2...                1.23   \n",
       "\n",
       "  3months_to_30092019 9months_to_30092020 9months_to_30092019  \n",
       "0                 915               2,391               2,839  \n",
       "1                 227                 465                 698  \n",
       "2                 211                 427                 666  \n",
       "3                 169                 346                 533  \n",
       "4                 168                 346                 529  \n",
       "5                   1                   —                   4  \n",
       "6                0.90                1.87                2.82  \n",
       "7                0.90                1.86                2.81  \n",
       "8                1.03                1.13                1.03  \n",
       "9                1.16                1.23                1.16  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tables[0]\n",
    "df = df.drop(df.columns[[1,5]], axis=1)  # drop columns: 1,5\n",
    "df = df.drop([0,5,12])                   # drop rows: 0,5,12\n",
    "df = df.reset_index(drop=True)           # reset index\n",
    "df.columns = ('Field','3months_to_30092020','3months_to_30092019','9months_to_30092020','9months_to_30092019') # rename columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043dc3e",
   "metadata": {
    "id": "TUsE_YcMbjZ_",
    "papermill": {
     "duration": 0.051634,
     "end_time": "2023-02-23T00:59:47.769701",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.718067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "During the cleaning phase, some of the values may need to be updated too (e.g. certain values in the Field column above).\n",
    "- Ideally the above cleaning operations would be done automatically.\n",
    "- In practice, tables have lots of nested structure (including the one we just extracted), \n",
    "- and it's still a hard research problem to do the cleaning reliably, (particularly the generation of the column names that we provided manually).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e479a39",
   "metadata": {
    "id": "Udj4WngyWapb",
    "papermill": {
     "duration": 0.049043,
     "end_time": "2023-02-23T00:59:47.868209",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.819166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading text from scanned document\n",
    "\n",
    "But what if my documents have been scanned? \n",
    "- In that case the task of extracting text from them is much more difficult.\n",
    "\n",
    "It is possible to extract text also from images, but you will need to have an Optical Character Recognition (OCR) system installed. \n",
    "We can use a combination of layout parsing and OCR to extract the text.\n",
    "- Layout parser is an opensource library to detect leyoutis in images: https://towardsdatascience.com/analyzing-document-layout-with-layoutparser-ed24d85f1d44\n",
    "- Tesseract is an opensource OCR system provided by Google. Some systems (such as Linux) come with Tesseract pre-installed. Others need to install it from here: https://tesseract-ocr.github.io/tessdoc/Home.html \n",
    "- If you have Tesseract installed, you can follow the instructions here to use it from Python: https://towardsdatascience.com/extracting-text-from-scanned-pdf-using-pytesseract-open-cv-cd670ee38052\n",
    "\n",
    "Give a look at the first link to see how it works, and try it yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c0afd",
   "metadata": {
    "id": "GzsfKKdGe2wd",
    "papermill": {
     "duration": 0.049483,
     "end_time": "2023-02-23T00:59:47.968027",
     "exception": false,
     "start_time": "2023-02-23T00:59:47.918544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 100.817522,
   "end_time": "2023-02-23T00:59:49.645054",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-23T00:58:08.827532",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
